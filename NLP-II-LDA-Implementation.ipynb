{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation - Implementation\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we perform Latent Dirichlet Allocation (LDA) to identify common topics in a set of documents. \n",
    "\n",
    "We use the **Gensim** topic modeling API. \n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\n",
    "Although there is a Scikit-Learn implementation of LDA, we prefer Gensim’s LDA as it provides a lot more built in functionality and applications for the LDA model such as a great Topic Coherence Pipeline or Dynamic Topic Modeling. \n",
    "\n",
    "\n",
    "We build an **end-to-end Natural Language Processing (NLP) pipeline**, starting with raw data and running through preparing, modeling, visualization.\n",
    "\n",
    "\n",
    "- Pre-process Data\n",
    "- Topic modeling with LDA\n",
    "- Determine Optimal Number of Topics\n",
    "- Visualizing topic models with pyLDAvis\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We use a dataset containing scientific papers publised in the 2015 Neural Information Processing Systems (NIPS) conference. It is one of the top machine learning conferences in the world. It covers topics ranging from deep learning and computer vision to cognitive science and reinforcement learning.\n",
    "\n",
    "The input CSV file contains one row for each of the 403 NIPS papers from 2015 conference. It includes the following fields\n",
    "\n",
    "- Id - unique identifier for the paper (equivalent to the one in NIPS's system)\n",
    "- Title - title of the paper\n",
    "- EventType - whether it's a poster, oral, or spotlight presentation\n",
    "- PdfName - filename for the PDF document\n",
    "- Abstract - text for the abstract (scraped from the NIPS website)\n",
    "- PaperText - raw text from the PDF document (created using the tool pdftotext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 20:00:00,732 : DEBUG : Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>EventType</th>\n",
       "      <th>PdfName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>PaperText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5677</td>\n",
       "      <td>Double or Nothing: Multiplicative Incentive Me...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5677-double-or-nothing-multiplicative-incentiv...</td>\n",
       "      <td>Crowdsourcing has gained immense popularity in...</td>\n",
       "      <td>Double or Nothing: Multiplicative\\nIncentive M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5941</td>\n",
       "      <td>Learning with Symmetric Label Noise: The Impor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5941-learning-with-symmetric-label-noise-the-i...</td>\n",
       "      <td>Convex potential minimisation is the de facto ...</td>\n",
       "      <td>Learning with Symmetric Label Noise: The\\nImpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6019-algorithmic-stability-and-uniform-general...</td>\n",
       "      <td>One of the central questions in statistical le...</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6035</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6035-adaptive-low-complexity-sequential-infere...</td>\n",
       "      <td>We develop a sequential low-complexity inferen...</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5978</td>\n",
       "      <td>Covariance-Controlled Adaptive Langevin Thermo...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5978-covariance-controlled-adaptive-langevin-t...</td>\n",
       "      <td>Monte Carlo sampling for Bayesian posterior in...</td>\n",
       "      <td>Covariance-Controlled Adaptive Langevin\\nTherm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Title  EventType  \\\n",
       "0  5677  Double or Nothing: Multiplicative Incentive Me...     Poster   \n",
       "1  5941  Learning with Symmetric Label Noise: The Impor...  Spotlight   \n",
       "2  6019   Algorithmic Stability and Uniform Generalization     Poster   \n",
       "3  6035  Adaptive Low-Complexity Sequential Inference f...     Poster   \n",
       "4  5978  Covariance-Controlled Adaptive Langevin Thermo...     Poster   \n",
       "\n",
       "                                             PdfName  \\\n",
       "0  5677-double-or-nothing-multiplicative-incentiv...   \n",
       "1  5941-learning-with-symmetric-label-noise-the-i...   \n",
       "2  6019-algorithmic-stability-and-uniform-general...   \n",
       "3  6035-adaptive-low-complexity-sequential-infere...   \n",
       "4  5978-covariance-controlled-adaptive-langevin-t...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Crowdsourcing has gained immense popularity in...   \n",
       "1  Convex potential minimisation is the de facto ...   \n",
       "2  One of the central questions in statistical le...   \n",
       "3  We develop a sequential low-complexity inferen...   \n",
       "4  Monte Carlo sampling for Bayesian posterior in...   \n",
       "\n",
       "                                           PaperText  \n",
       "0  Double or Nothing: Multiplicative\\nIncentive M...  \n",
       "1  Learning with Symmetric Label Noise: The\\nImpo...  \n",
       "2  Algorithmic Stability and Uniform Generalizati...  \n",
       "3  Adaptive Low-Complexity Sequential Inference f...  \n",
       "4  Covariance-Controlled Adaptive Langevin\\nTherm...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/hasan/datasets/NIPS2015_Papers.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Data\n",
    "\n",
    "DataFrame’s info() method is useful to get a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403 entries, 0 to 402\n",
      "Data columns (total 6 columns):\n",
      "Id           403 non-null int64\n",
      "Title        403 non-null object\n",
      "EventType    403 non-null object\n",
      "PdfName      403 non-null object\n",
      "Abstract     403 non-null object\n",
      "PaperText    403 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 19.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension the Data\n",
    "\n",
    "Get the dimension (number of rows and columns) of the data using DataFrame's shape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data:  (403, 6)\n",
      "No. of Rows: 403\n",
      "No. of Columns: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the data: \", df.shape)\n",
    "\n",
    "no_of_rows = df.shape[0]\n",
    "no_of_columns = df.shape[1]\n",
    "\n",
    "print(\"No. of Rows: %d\" % no_of_rows)\n",
    "print(\"No. of Columns: %d\" % no_of_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the DataFrame Object into a 2D Array of Documents\n",
    "\n",
    "We convert the documents from DataFrame object to an array of documents.\n",
    "\n",
    "It's a 2D array in which each row reprents a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the documents array:  (403,)\n"
     ]
    }
   ],
   "source": [
    "docs_array = array(df['PaperText'])\n",
    "\n",
    "print(\"Dimension of the documents array: \", docs_array.shape)\n",
    "\n",
    "# Display the first document\n",
    "#print(docs_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the Data\n",
    "\n",
    "\n",
    "We pre-process the data as follows. \n",
    "\n",
    "- Convert to lowercase \n",
    "- Tokenize (split the documents into tokens or words)\n",
    "- Remove numbers, but not words that contain numbers\n",
    "- Remove words that are only one character\n",
    "- Lemmatize the tokens/words\n",
    "\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "We tokenize the text using a regular expression tokenizer from NLTK. We remove numeric tokens and tokens that are only a single character, as they don’t tend to be useful, and the dataset contains a lot of them.\n",
    "\n",
    "\n",
    "The NLTK Regular-Expression Tokenizer class \"RegexpTokenizer\" splits a string into substrings using a regular expression. We use the regular expression \"\\w+\" to matche token of words. \n",
    "\n",
    "See the following two links for a list of regular expressions and NLTK tokenize module.\n",
    "https://github.com/tartley/python-regex-cheatsheet/blob/master/cheatsheet.rst\n",
    "https://www.nltk.org/api/nltk.tokenize.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Convert the 2D Document Array into a 2D Array of Tokenized Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # Tokenize the words.\n",
    "    \n",
    "    for idx in range(len(docs)):\n",
    "        docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "    # Remove numbers, but not words that contain numbers.\n",
    "    docs = [[token for token in doc if not token.isdigit()] for doc in docs]\n",
    "    \n",
    "    # Remove words that are only one character.\n",
    "    docs = [[token for token in doc if len(token) > 3] for doc in docs]\n",
    "    \n",
    "    # Lemmatize all words in documents.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "  \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the 2D Document Array into a 1D Array of Tokenized Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.06 s, sys: 182 ms, total: 8.24 s\n",
      "Wall time: 8.25 s\n"
     ]
    }
   ],
   "source": [
    "# Convert the 2D Document Array into a 1D Array of Tokenized Words\n",
    "%time docs = docs_preprocessor(docs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the 2D Array of Tokenized Documents:  403\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the 2D Array of Tokenized Documents: \", len(docs))\n",
    "\n",
    "# Display the first two document\n",
    "#print(docs[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Bigrams/Trigrams:\n",
    "\n",
    "\n",
    "When topics are very similar, we may **use phrases** rather than single/individual words to distinguis each topic. \n",
    "\n",
    "Thus, we compute both bigrams and trigrams. Depending on the dataset it may not be necessary to create trigrams.\n",
    "\n",
    "Note that we only keep the **frequent** phrases (bigrams/trigrams).\n",
    "\n",
    "#### Bigrams\n",
    "Bigrams are sets of two adjacent words. Using bigrams we can get phrases like “machine_learning” in our output (spaces are replaced with underscores). Without bigrams we would only get “machine” and “learning”.\n",
    "\n",
    "Note that in the code below, we find bigrams and then add them to the original data, because we would like to keep the words “machine” and “learning” as well as the bigram “machine_learning”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:07:56,786 : INFO : collecting all words and their counts\n",
      "2020-02-27 19:07:56,787 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2020-02-27 19:07:58,882 : INFO : collected 556123 word types from a corpus of 1141175 words (unigram + bigrams) and 403 sentences\n",
      "2020-02-27 19:07:58,883 : INFO : using 556123 counts as vocab in Phrases<0 vocab, min_count=10, threshold=10.0, max_vocab_size=40000000>\n",
      "2020-02-27 19:07:58,884 : INFO : collecting all words and their counts\n",
      "2020-02-27 19:07:58,897 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2020-02-27 19:08:05,368 : INFO : collected 616916 word types from a corpus of 1020757 words (unigram + bigrams) and 403 sentences\n",
      "2020-02-27 19:08:05,369 : INFO : using 616916 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 10 times or more).\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "trigram = Phrases(bigram[docs])\n",
    "\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "    for token in trigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Rare and Common Tokens/Words\n",
    "\n",
    "We remove rare words and common words based on their document frequency. \n",
    "\n",
    "For example, we may remove words that appear in less than 10 documents or in more than 20% of the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:14,827 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-02-27 19:08:15,910 : INFO : built Dictionary(39534 unique tokens: ['abdel', 'ability', 'about', 'above', 'abstract']...) from 403 documents (total 1544630 corpus positions)\n",
      "2020-02-27 19:08:15,986 : INFO : discarding 33533 tokens: [('abdel', 4), ('ability', 104), ('about', 266), ('above', 300), ('abstract', 402), ('according', 204), ('accuracy', 210), ('across', 183), ('across_trial', 7), ('added', 85)]...\n",
      "2020-02-27 19:08:15,987 : INFO : keeping 6001 tokens which were in no less than 10 and no more than 80 (=20.0%) documents\n",
      "2020-02-27 19:08:16,002 : DEBUG : rebuilding dictionary, shrinking gaps\n",
      "2020-02-27 19:08:16,008 : INFO : resulting dictionary: Dictionary(6001 unique tokens: ['accessed', 'acoustic', 'acquisition', 'additive', 'address_this']...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 39534\n",
      "Number of unique words after removing rare and common words: 6001\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "print('Number of unique words in initital documents:', len(dictionary))\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 20% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
    "print('Number of unique words after removing rare and common words:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words Representation of Data\n",
    "\n",
    "\n",
    "Finally, we transform the documents to a **vectorized form**. \n",
    "\n",
    "We simply compute the frequency of each word, including the bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 6001\n",
      "Number of documents: 403\n"
     ]
    }
   ],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the LDA Model\n",
    "\n",
    "We use the gensim.models.LdaModel class for performing LDA.\n",
    "\n",
    "We need to set the parameters of the LdaModel object carefully. The full list of the parameters are given:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\n",
    "\n",
    "#### Below we discuss the setting of some of the key parameters.\n",
    "\n",
    "- num_topics (int, optional) – The number of requested latent topics to be extracted from the training corpus.\n",
    "\n",
    " \n",
    "LDA is an unsupervised technique, meaning that we don't know prior to running the model how many topics exits in our corpus. It depends on the data and the application. We may use the following two technique to determine the number of topics.\n",
    "\n",
    "\n",
    "        Technique 1: Topic Coherence \n",
    "The main technique to determine the number of topics is **Topic coherence**:\n",
    "http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
    "\n",
    "\n",
    "        Technique 2: Visualizing Inter-Topic Distance \n",
    "Use the LDA visualization tool pyLDAvis to observe Intertopic Distance Map (discussed later). By varying the number of topics we could determine the optimal value from the visualization.\n",
    "\n",
    "We **use both techniques** to determine the optimal number of topics.\n",
    "\n",
    "\n",
    "- chunksize (int, optional) – Number of documents to be used in each training chunk.\n",
    "\n",
    "It controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory. \n",
    "\n",
    "We set chunksize = 2000, which is more than the amount of documents. Thus, it processes all the data in one go. \n",
    "\n",
    "Chunksize can however influence the quality of the model.\n",
    "\n",
    "\n",
    "- passes (int, optional) – Number of passes through the corpus during training.\n",
    "\n",
    "It controls how often we train the model on the entire corpus. Another word for passes might be “epochs”. \n",
    "\n",
    "\n",
    "- iterations (int, optional) – Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
    "\n",
    "It is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. \n",
    "\n",
    "        It is important to set the number of “passes” and “iterations” high enough.\n",
    "\n",
    "\n",
    "\n",
    "#### How to Set \"passes\" and \"iterations\":\n",
    "\n",
    "First, enable logging and set eval_every = 1 (however, it might slow down, so, we use None) in LdaModel. \n",
    "\n",
    "When training the model look for a line in the log that looks something like this:\n",
    "\n",
    "        2020-02-25 19:07:04,716 : DEBUG : 49/403 documents converged within 400 iterations\n",
    "\n",
    "If we set passes = 20, we will see this line 20 times. \n",
    "\n",
    "### Important: We need to make sure that by the final passes, most of the documents have converged. \n",
    "\n",
    "For example, if passes = 20 and iterations = 400, then, we should see something like following:\n",
    "\n",
    "\n",
    "        2020-02-25 19:07:18,041 : INFO : PROGRESS: pass 19, at document #403/403\n",
    "        2020-02-25 19:07:18,042 : DEBUG : performing inference on a chunk of 403 documents\n",
    "        2020-02-25 19:07:18,627 : DEBUG : 402/403 documents converged within 400 iterations\n",
    "\n",
    "Thus, want to choose both passes and iterations to be high enough for this to happen.\n",
    "\n",
    "\n",
    "- eval_every (int, optional) – Log perplexity is estimated every that many updates. Setting this to 1 slows down training by ~2x.\n",
    "\n",
    "\n",
    "- alpha ({numpy.ndarray, str}, optional): Can be set to an 1D array of length equal to the number of expected topics that expresses our a-priori belief for the each topics’ probability. \n",
    "\n",
    "Alternatively default prior selecting strategies can be employed by supplying a string:\n",
    "\n",
    "        ’asymmetric’: Uses a fixed normalized asymmetric prior of 1.0 / topicno.\n",
    "\n",
    "        ’auto’: Learns an asymmetric prior from the corpus (not available if distributed==True).\n",
    "        \n",
    "        \n",
    "- eta ({float, np.array, str}, optional) – A-priori belief on word probability.\n",
    "\n",
    "It can be:\n",
    "\n",
    "        scalar for a symmetric prior over topic/word probability,\n",
    "\n",
    "        vector of length num_words to denote an asymmetric user defined probability for each word,\n",
    "\n",
    "        matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination,\n",
    "\n",
    "        the string ‘auto’ to learn the asymmetric prior from the data.\n",
    "\n",
    "\n",
    "We set alpha = 'auto' and eta = 'auto'. Again this is somewhat technical, but essentially we are automatically learning two parameters in the model that we usually would have to specify explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:16,576 : INFO : using autotuned alpha, starting with [0.25, 0.25, 0.25, 0.25]\n",
      "2020-02-27 19:08:16,579 : INFO : using serial LDA version on this node\n",
      "2020-02-27 19:08:16,585 : INFO : running online (multi-pass) LDA training, 4 topics, 20 passes over the supplied corpus of 403 documents, updating model once every 403 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2020-02-27 19:08:16,586 : INFO : PROGRESS: pass 0, at document #403/403\n",
      "2020-02-27 19:08:16,586 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:19,757 : DEBUG : 60/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:19,761 : INFO : optimized alpha [0.06745957, 0.14463517, 0.05922535, 0.19062406]\n",
      "2020-02-27 19:08:19,761 : DEBUG : updating topics\n",
      "2020-02-27 19:08:19,765 : INFO : topic #0 (0.067): 0.004*\"proposal\" + 0.003*\"covariance_matrix\" + 0.003*\"variational_inference\" + 0.003*\"data_set\" + 0.003*\"document\" + 0.003*\"hidden_unit\" + 0.003*\"convolutional\" + 0.003*\"ground_truth\" + 0.003*\"gibbs_sampling\" + 0.003*\"fully_connected\"\n",
      "2020-02-27 19:08:19,766 : INFO : topic #1 (0.145): 0.008*\"regret\" + 0.004*\"bandit\" + 0.003*\"sample_complexity\" + 0.003*\"time_step\" + 0.003*\"regret_bound\" + 0.003*\"query\" + 0.003*\"policy\" + 0.003*\"active_learning\" + 0.002*\"game\" + 0.002*\"player\"\n",
      "2020-02-27 19:08:19,767 : INFO : topic #2 (0.059): 0.007*\"matrix_completion\" + 0.004*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.003*\"line_search\" + 0.003*\"bayesian_network\" + 0.003*\"completion\" + 0.003*\"recovery\" + 0.002*\"data_set\" + 0.002*\"gradient_descent\" + 0.002*\"reward\"\n",
      "2020-02-27 19:08:19,768 : INFO : topic #3 (0.191): 0.003*\"convergence_rate\" + 0.003*\"tensor\" + 0.003*\"gaussian_process\" + 0.003*\"step_size\" + 0.003*\"generative_model\" + 0.003*\"markov_chain\" + 0.002*\"graphical_model\" + 0.002*\"random_walk\" + 0.002*\"variational_inference\" + 0.002*\"gradient_descent\"\n",
      "2020-02-27 19:08:19,769 : INFO : topic diff=0.863012, rho=1.000000\n",
      "2020-02-27 19:08:19,775 : INFO : PROGRESS: pass 1, at document #403/403\n",
      "2020-02-27 19:08:19,776 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:21,146 : DEBUG : 379/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:21,150 : INFO : optimized alpha [0.061164368, 0.08634836, 0.055044115, 0.09760198]\n",
      "2020-02-27 19:08:21,151 : DEBUG : updating topics\n",
      "2020-02-27 19:08:21,154 : INFO : topic #0 (0.061): 0.005*\"proposal\" + 0.004*\"convolutional\" + 0.004*\"document\" + 0.004*\"fully_connected\" + 0.004*\"hidden_unit\" + 0.003*\"variational_inference\" + 0.003*\"data_set\" + 0.003*\"ground_truth\" + 0.003*\"gibbs_sampling\" + 0.003*\"covariance_matrix\"\n",
      "2020-02-27 19:08:21,155 : INFO : topic #1 (0.086): 0.009*\"regret\" + 0.005*\"bandit\" + 0.004*\"query\" + 0.004*\"active_learning\" + 0.004*\"regret_bound\" + 0.004*\"policy\" + 0.004*\"sample_complexity\" + 0.003*\"time_step\" + 0.003*\"game\" + 0.003*\"online_learning\"\n",
      "2020-02-27 19:08:21,156 : INFO : topic #2 (0.055): 0.007*\"matrix_completion\" + 0.005*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"line_search\" + 0.004*\"recovery\" + 0.003*\"completion\" + 0.003*\"bayesian_network\" + 0.003*\"gradient_descent\" + 0.003*\"primal_dual\" + 0.002*\"graphical_model\"\n",
      "2020-02-27 19:08:21,158 : INFO : topic #3 (0.098): 0.004*\"gaussian_process\" + 0.004*\"convergence_rate\" + 0.004*\"tensor\" + 0.003*\"step_size\" + 0.003*\"generative_model\" + 0.003*\"markov_chain\" + 0.003*\"variational_inference\" + 0.002*\"graphical_model\" + 0.002*\"random_walk\" + 0.002*\"embedding\"\n",
      "2020-02-27 19:08:21,158 : INFO : topic diff=0.208178, rho=0.577350\n",
      "2020-02-27 19:08:21,164 : INFO : PROGRESS: pass 2, at document #403/403\n",
      "2020-02-27 19:08:21,164 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:22,038 : DEBUG : 395/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:22,041 : INFO : optimized alpha [0.057430666, 0.07115031, 0.0538886, 0.08504181]\n",
      "2020-02-27 19:08:22,042 : DEBUG : updating topics\n",
      "2020-02-27 19:08:22,046 : INFO : topic #0 (0.057): 0.005*\"proposal\" + 0.004*\"convolutional\" + 0.004*\"fully_connected\" + 0.004*\"hidden_unit\" + 0.004*\"document\" + 0.003*\"lstm\" + 0.003*\"variational_inference\" + 0.003*\"ground_truth\" + 0.003*\"recurrent_neural\" + 0.003*\"data_set\"\n",
      "2020-02-27 19:08:22,047 : INFO : topic #1 (0.071): 0.011*\"regret\" + 0.006*\"bandit\" + 0.005*\"active_learning\" + 0.004*\"policy\" + 0.004*\"query\" + 0.004*\"regret_bound\" + 0.004*\"game\" + 0.004*\"sample_complexity\" + 0.004*\"time_step\" + 0.003*\"reward\"\n",
      "2020-02-27 19:08:22,048 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"line_search\" + 0.004*\"recovery\" + 0.003*\"gradient_descent\" + 0.003*\"completion\" + 0.003*\"nuclear_norm\" + 0.003*\"bayesian_network\" + 0.003*\"logistic_regression\"\n",
      "2020-02-27 19:08:22,049 : INFO : topic #3 (0.085): 0.005*\"gaussian_process\" + 0.004*\"convergence_rate\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.003*\"generative_model\" + 0.003*\"markov_chain\" + 0.003*\"variational_inference\" + 0.003*\"embedding\" + 0.002*\"graphical_model\" + 0.002*\"random_walk\"\n",
      "2020-02-27 19:08:22,050 : INFO : topic diff=0.174119, rho=0.500000\n",
      "2020-02-27 19:08:22,056 : INFO : PROGRESS: pass 3, at document #403/403\n",
      "2020-02-27 19:08:22,057 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:22,793 : DEBUG : 399/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:22,797 : INFO : optimized alpha [0.055065274, 0.063212775, 0.05371317, 0.07714746]\n",
      "2020-02-27 19:08:22,798 : DEBUG : updating topics\n",
      "2020-02-27 19:08:22,801 : INFO : topic #0 (0.055): 0.005*\"convolutional\" + 0.005*\"proposal\" + 0.004*\"fully_connected\" + 0.004*\"hidden_unit\" + 0.004*\"lstm\" + 0.004*\"recurrent_neural\" + 0.004*\"document\" + 0.004*\"recurrent\" + 0.004*\"ground_truth\" + 0.003*\"deep_learning\"\n",
      "2020-02-27 19:08:22,802 : INFO : topic #1 (0.063): 0.011*\"regret\" + 0.006*\"bandit\" + 0.005*\"active_learning\" + 0.005*\"policy\" + 0.005*\"query\" + 0.004*\"regret_bound\" + 0.004*\"game\" + 0.004*\"reward\" + 0.004*\"sample_complexity\" + 0.004*\"time_step\"\n",
      "2020-02-27 19:08:22,803 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.003*\"gradient_descent\" + 0.003*\"completion\" + 0.003*\"nuclear_norm\" + 0.003*\"logistic_regression\" + 0.003*\"graphical_model\"\n",
      "2020-02-27 19:08:22,804 : INFO : topic #3 (0.077): 0.006*\"gaussian_process\" + 0.004*\"convergence_rate\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.003*\"variational_inference\" + 0.003*\"markov_chain\" + 0.003*\"generative_model\" + 0.003*\"embedding\" + 0.002*\"graphical_model\" + 0.002*\"posterior_distribution\"\n",
      "2020-02-27 19:08:22,805 : INFO : topic diff=0.148972, rho=0.447214\n",
      "2020-02-27 19:08:22,811 : INFO : PROGRESS: pass 4, at document #403/403\n",
      "2020-02-27 19:08:22,811 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:23,477 : DEBUG : 398/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:23,481 : INFO : optimized alpha [0.0534921, 0.058383755, 0.05379151, 0.07271609]\n",
      "2020-02-27 19:08:23,481 : DEBUG : updating topics\n",
      "2020-02-27 19:08:23,485 : INFO : topic #0 (0.053): 0.005*\"convolutional\" + 0.005*\"proposal\" + 0.005*\"fully_connected\" + 0.004*\"hidden_unit\" + 0.004*\"recurrent_neural\" + 0.004*\"recurrent\" + 0.004*\"lstm\" + 0.004*\"document\" + 0.004*\"deep_learning\" + 0.004*\"ground_truth\"\n",
      "2020-02-27 19:08:23,486 : INFO : topic #1 (0.058): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"active_learning\" + 0.005*\"policy\" + 0.005*\"query\" + 0.005*\"regret_bound\" + 0.005*\"game\" + 0.004*\"reward\" + 0.004*\"sample_complexity\" + 0.004*\"online_learning\"\n",
      "2020-02-27 19:08:23,487 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.003*\"gradient_descent\" + 0.003*\"logistic_regression\" + 0.003*\"nuclear_norm\" + 0.003*\"graphical_model\" + 0.003*\"completion\"\n",
      "2020-02-27 19:08:23,488 : INFO : topic #3 (0.073): 0.006*\"gaussian_process\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.004*\"convergence_rate\" + 0.003*\"variational_inference\" + 0.003*\"markov_chain\" + 0.003*\"embedding\" + 0.003*\"generative_model\" + 0.003*\"posterior_distribution\" + 0.002*\"mcmc\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:23,489 : INFO : topic diff=0.128294, rho=0.408248\n",
      "2020-02-27 19:08:23,495 : INFO : PROGRESS: pass 5, at document #403/403\n",
      "2020-02-27 19:08:23,496 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:24,186 : DEBUG : 401/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:24,190 : INFO : optimized alpha [0.052063763, 0.055151038, 0.05386876, 0.0699383]\n",
      "2020-02-27 19:08:24,191 : DEBUG : updating topics\n",
      "2020-02-27 19:08:24,195 : INFO : topic #0 (0.052): 0.005*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"proposal\" + 0.004*\"recurrent_neural\" + 0.004*\"recurrent\" + 0.004*\"hidden_unit\" + 0.004*\"lstm\" + 0.004*\"deep_learning\" + 0.004*\"document\" + 0.004*\"ground_truth\"\n",
      "2020-02-27 19:08:24,196 : INFO : topic #1 (0.055): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"active_learning\" + 0.006*\"policy\" + 0.005*\"game\" + 0.005*\"reward\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.004*\"sample_complexity\" + 0.004*\"online_learning\"\n",
      "2020-02-27 19:08:24,197 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.004*\"gradient_descent\" + 0.003*\"strongly_convex\" + 0.003*\"logistic_regression\" + 0.003*\"convergence_rate\" + 0.003*\"nuclear_norm\"\n",
      "2020-02-27 19:08:24,199 : INFO : topic #3 (0.070): 0.007*\"gaussian_process\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.004*\"variational_inference\" + 0.004*\"convergence_rate\" + 0.003*\"markov_chain\" + 0.003*\"posterior_distribution\" + 0.003*\"embedding\" + 0.003*\"generative_model\" + 0.003*\"mcmc\"\n",
      "2020-02-27 19:08:24,200 : INFO : topic diff=0.112210, rho=0.377964\n",
      "2020-02-27 19:08:24,207 : INFO : PROGRESS: pass 6, at document #403/403\n",
      "2020-02-27 19:08:24,208 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:24,846 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:24,850 : INFO : optimized alpha [0.051053774, 0.05317078, 0.05405636, 0.06795421]\n",
      "2020-02-27 19:08:24,851 : DEBUG : updating topics\n",
      "2020-02-27 19:08:24,854 : INFO : topic #0 (0.051): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"proposal\" + 0.005*\"recurrent_neural\" + 0.005*\"recurrent\" + 0.004*\"hidden_unit\" + 0.004*\"lstm\" + 0.004*\"deep_learning\" + 0.004*\"hidden_layer\" + 0.004*\"document\"\n",
      "2020-02-27 19:08:24,856 : INFO : topic #1 (0.053): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"active_learning\" + 0.006*\"policy\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.004*\"sample_complexity\" + 0.004*\"item\"\n",
      "2020-02-27 19:08:24,857 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.004*\"gradient_descent\" + 0.004*\"convergence_rate\" + 0.003*\"strongly_convex\" + 0.003*\"logistic_regression\" + 0.003*\"nuclear_norm\"\n",
      "2020-02-27 19:08:24,858 : INFO : topic #3 (0.068): 0.007*\"gaussian_process\" + 0.004*\"variational_inference\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.003*\"markov_chain\" + 0.003*\"convergence_rate\" + 0.003*\"posterior_distribution\" + 0.003*\"embedding\" + 0.003*\"mcmc\" + 0.003*\"generative_model\"\n",
      "2020-02-27 19:08:24,859 : INFO : topic diff=0.099215, rho=0.353553\n",
      "2020-02-27 19:08:24,865 : INFO : PROGRESS: pass 7, at document #403/403\n",
      "2020-02-27 19:08:24,865 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:25,460 : DEBUG : 400/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:25,464 : INFO : optimized alpha [0.050182804, 0.051860593, 0.054119036, 0.06659172]\n",
      "2020-02-27 19:08:25,465 : DEBUG : updating topics\n",
      "2020-02-27 19:08:25,469 : INFO : topic #0 (0.050): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"proposal\" + 0.005*\"recurrent_neural\" + 0.004*\"hidden_unit\" + 0.004*\"lstm\" + 0.004*\"deep_learning\" + 0.004*\"hidden_layer\" + 0.004*\"document\"\n",
      "2020-02-27 19:08:25,471 : INFO : topic #1 (0.052): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"active_learning\" + 0.006*\"policy\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.004*\"item\" + 0.004*\"agent\"\n",
      "2020-02-27 19:08:25,472 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"convergence_rate\" + 0.004*\"line_search\" + 0.004*\"gradient_descent\" + 0.003*\"strongly_convex\" + 0.003*\"logistic_regression\" + 0.003*\"step_size\"\n",
      "2020-02-27 19:08:25,473 : INFO : topic #3 (0.067): 0.007*\"gaussian_process\" + 0.004*\"variational_inference\" + 0.004*\"tensor\" + 0.004*\"step_size\" + 0.004*\"markov_chain\" + 0.003*\"posterior_distribution\" + 0.003*\"convergence_rate\" + 0.003*\"mcmc\" + 0.003*\"embedding\" + 0.003*\"covariance_matrix\"\n",
      "2020-02-27 19:08:25,474 : INFO : topic diff=0.088318, rho=0.333333\n",
      "2020-02-27 19:08:25,481 : INFO : PROGRESS: pass 8, at document #403/403\n",
      "2020-02-27 19:08:25,481 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:26,099 : DEBUG : 400/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:26,103 : INFO : optimized alpha [0.04941558, 0.050913066, 0.054190185, 0.0655083]\n",
      "2020-02-27 19:08:26,104 : DEBUG : updating topics\n",
      "2020-02-27 19:08:26,108 : INFO : topic #0 (0.049): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"proposal\" + 0.005*\"hidden_unit\" + 0.004*\"deep_learning\" + 0.004*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"ground_truth\"\n",
      "2020-02-27 19:08:26,109 : INFO : topic #1 (0.051): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.004*\"item\" + 0.004*\"agent\"\n",
      "2020-02-27 19:08:26,110 : INFO : topic #2 (0.054): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.004*\"convergence_rate\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.004*\"gradient_descent\" + 0.004*\"strongly_convex\" + 0.003*\"logistic_regression\" + 0.003*\"step_size\"\n",
      "2020-02-27 19:08:26,111 : INFO : topic #3 (0.066): 0.007*\"gaussian_process\" + 0.004*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"step_size\" + 0.004*\"tensor\" + 0.003*\"posterior_distribution\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"convergence_rate\" + 0.003*\"embedding\"\n",
      "2020-02-27 19:08:26,112 : INFO : topic diff=0.079425, rho=0.316228\n",
      "2020-02-27 19:08:26,118 : INFO : PROGRESS: pass 9, at document #403/403\n",
      "2020-02-27 19:08:26,119 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:26,721 : DEBUG : 400/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:26,726 : INFO : optimized alpha [0.048919816, 0.050338052, 0.054684885, 0.06503872]\n",
      "2020-02-27 19:08:26,727 : DEBUG : updating topics\n",
      "2020-02-27 19:08:26,730 : INFO : topic #0 (0.049): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"proposal\" + 0.005*\"hidden_unit\" + 0.004*\"deep_learning\" + 0.004*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"ground_truth\"\n",
      "2020-02-27 19:08:26,731 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.004*\"item\" + 0.004*\"agent\"\n",
      "2020-02-27 19:08:26,732 : INFO : topic #2 (0.055): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.005*\"convergence_rate\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.004*\"gradient_descent\" + 0.004*\"strongly_convex\" + 0.003*\"regularization_parameter\" + 0.003*\"logistic_regression\"\n",
      "2020-02-27 19:08:26,733 : INFO : topic #3 (0.065): 0.007*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"step_size\" + 0.003*\"tensor\" + 0.003*\"posterior_distribution\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"embedding\" + 0.003*\"sampler\"\n",
      "2020-02-27 19:08:26,734 : INFO : topic diff=0.071841, rho=0.301511\n",
      "2020-02-27 19:08:26,740 : INFO : PROGRESS: pass 10, at document #403/403\n",
      "2020-02-27 19:08:26,740 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:27,357 : DEBUG : 401/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:27,363 : INFO : optimized alpha [0.04857666, 0.050115354, 0.055232108, 0.064878836]\n",
      "2020-02-27 19:08:27,364 : DEBUG : updating topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:27,368 : INFO : topic #0 (0.049): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"proposal\" + 0.005*\"hidden_unit\" + 0.005*\"deep_learning\" + 0.004*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"ground_truth\"\n",
      "2020-02-27 19:08:27,369 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"submodular\" + 0.004*\"item\"\n",
      "2020-02-27 19:08:27,371 : INFO : topic #2 (0.055): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.005*\"convergence_rate\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"gradient_descent\" + 0.004*\"line_search\" + 0.004*\"strongly_convex\" + 0.004*\"regularization_parameter\" + 0.004*\"step_size\"\n",
      "2020-02-27 19:08:27,372 : INFO : topic #3 (0.065): 0.007*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.003*\"posterior_distribution\" + 0.003*\"step_size\" + 0.003*\"tensor\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"sampler\" + 0.003*\"embedding\"\n",
      "2020-02-27 19:08:27,373 : INFO : topic diff=0.065490, rho=0.288675\n",
      "2020-02-27 19:08:27,380 : INFO : PROGRESS: pass 11, at document #403/403\n",
      "2020-02-27 19:08:27,380 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:28,036 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:28,042 : INFO : optimized alpha [0.048373662, 0.04995466, 0.05576009, 0.06482928]\n",
      "2020-02-27 19:08:28,044 : DEBUG : updating topics\n",
      "2020-02-27 19:08:28,047 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"proposal\" + 0.005*\"hidden_unit\" + 0.005*\"deep_learning\" + 0.004*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:28,049 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"submodular\" + 0.004*\"item\"\n",
      "2020-02-27 19:08:28,050 : INFO : topic #2 (0.056): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.005*\"convergence_rate\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"gradient_descent\" + 0.004*\"line_search\" + 0.004*\"strongly_convex\" + 0.004*\"regularization_parameter\" + 0.004*\"step_size\"\n",
      "2020-02-27 19:08:28,051 : INFO : topic #3 (0.065): 0.008*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"step_size\" + 0.003*\"tensor\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"sampler\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:28,052 : INFO : topic diff=0.059755, rho=0.277350\n",
      "2020-02-27 19:08:28,058 : INFO : PROGRESS: pass 12, at document #403/403\n",
      "2020-02-27 19:08:28,059 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:28,579 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:28,583 : INFO : optimized alpha [0.048339754, 0.049970284, 0.056253053, 0.064995795]\n",
      "2020-02-27 19:08:28,584 : DEBUG : updating topics\n",
      "2020-02-27 19:08:28,587 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"deep_learning\" + 0.005*\"hidden_unit\" + 0.005*\"proposal\" + 0.004*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:28,589 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"submodular\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:28,590 : INFO : topic #2 (0.056): 0.007*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.005*\"convergence_rate\" + 0.004*\"sample_complexity\" + 0.004*\"gradient_descent\" + 0.004*\"recovery\" + 0.004*\"line_search\" + 0.004*\"regularization_parameter\" + 0.004*\"strongly_convex\" + 0.004*\"step_size\"\n",
      "2020-02-27 19:08:28,591 : INFO : topic #3 (0.065): 0.008*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"step_size\" + 0.003*\"tensor\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"sampler\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:28,592 : INFO : topic diff=0.054857, rho=0.267261\n",
      "2020-02-27 19:08:28,598 : INFO : PROGRESS: pass 13, at document #403/403\n",
      "2020-02-27 19:08:28,598 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:29,233 : DEBUG : 403/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:29,237 : INFO : optimized alpha [0.04828247, 0.050036263, 0.05668933, 0.06515189]\n",
      "2020-02-27 19:08:29,238 : DEBUG : updating topics\n",
      "2020-02-27 19:08:29,241 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"deep_learning\" + 0.005*\"hidden_unit\" + 0.005*\"proposal\" + 0.005*\"lstm\" + 0.004*\"hidden_layer\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:29,243 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"submodular\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:29,244 : INFO : topic #2 (0.057): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.005*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"regularization_parameter\" + 0.004*\"strongly_convex\" + 0.004*\"step_size\" + 0.004*\"line_search\"\n",
      "2020-02-27 19:08:29,246 : INFO : topic #3 (0.065): 0.008*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"step_size\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"sampler\" + 0.003*\"tensor\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:29,246 : INFO : topic diff=0.050601, rho=0.258199\n",
      "2020-02-27 19:08:29,253 : INFO : PROGRESS: pass 14, at document #403/403\n",
      "2020-02-27 19:08:29,254 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:29,809 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:29,812 : INFO : optimized alpha [0.048249707, 0.050156564, 0.057260208, 0.065316044]\n",
      "2020-02-27 19:08:29,813 : DEBUG : updating topics\n",
      "2020-02-27 19:08:29,816 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"deep_learning\" + 0.005*\"hidden_unit\" + 0.005*\"proposal\" + 0.005*\"lstm\" + 0.005*\"hidden_layer\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:29,818 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"reward\" + 0.005*\"submodular\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:29,819 : INFO : topic #2 (0.057): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"regularization_parameter\" + 0.004*\"step_size\" + 0.004*\"singular_value\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:29,820 : INFO : topic #3 (0.065): 0.008*\"gaussian_process\" + 0.005*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"covariance_matrix\" + 0.003*\"sampler\" + 0.003*\"step_size\" + 0.003*\"mcmc\" + 0.003*\"tensor\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:29,821 : INFO : topic diff=0.046728, rho=0.250000\n",
      "2020-02-27 19:08:29,826 : INFO : PROGRESS: pass 15, at document #403/403\n",
      "2020-02-27 19:08:29,827 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:30,371 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:30,375 : INFO : optimized alpha [0.048340783, 0.050327275, 0.05791801, 0.06549818]\n",
      "2020-02-27 19:08:30,376 : DEBUG : updating topics\n",
      "2020-02-27 19:08:30,380 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"deep_learning\" + 0.005*\"hidden_unit\" + 0.005*\"proposal\" + 0.005*\"lstm\" + 0.005*\"hidden_layer\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:30,381 : INFO : topic #1 (0.050): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"submodular\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:30,382 : INFO : topic #2 (0.058): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"sample_complexity\" + 0.004*\"singular_value\" + 0.004*\"step_size\" + 0.004*\"recovery\" + 0.004*\"regularization_parameter\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:30,384 : INFO : topic #3 (0.065): 0.008*\"gaussian_process\" + 0.006*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"sampler\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"step_size\" + 0.003*\"mixture_model\" + 0.003*\"graphical_model\"\n",
      "2020-02-27 19:08:30,385 : INFO : topic diff=0.043159, rho=0.242536\n",
      "2020-02-27 19:08:30,391 : INFO : PROGRESS: pass 16, at document #403/403\n",
      "2020-02-27 19:08:30,392 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:30,936 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:30,940 : INFO : optimized alpha [0.048441563, 0.05053887, 0.058612633, 0.06578448]\n",
      "2020-02-27 19:08:30,941 : DEBUG : updating topics\n",
      "2020-02-27 19:08:30,945 : INFO : topic #0 (0.048): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"recurrent_neural\" + 0.005*\"deep_learning\" + 0.005*\"hidden_unit\" + 0.005*\"proposal\" + 0.005*\"hidden_layer\" + 0.005*\"lstm\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:30,946 : INFO : topic #1 (0.051): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"submodular\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:30,948 : INFO : topic #2 (0.059): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"singular_value\" + 0.004*\"step_size\" + 0.004*\"sample_complexity\" + 0.004*\"regularization_parameter\" + 0.004*\"recovery\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:30,949 : INFO : topic #3 (0.066): 0.008*\"gaussian_process\" + 0.006*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"sampler\" + 0.003*\"covariance_matrix\" + 0.003*\"mcmc\" + 0.003*\"step_size\" + 0.003*\"graphical_model\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:30,950 : INFO : topic diff=0.039999, rho=0.235702\n",
      "2020-02-27 19:08:30,957 : INFO : PROGRESS: pass 17, at document #403/403\n",
      "2020-02-27 19:08:30,957 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:31,496 : DEBUG : 403/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:31,501 : INFO : optimized alpha [0.048541285, 0.050781578, 0.059254415, 0.06615236]\n",
      "2020-02-27 19:08:31,502 : DEBUG : updating topics\n",
      "2020-02-27 19:08:31,505 : INFO : topic #0 (0.049): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"deep_learning\" + 0.005*\"recurrent_neural\" + 0.005*\"hidden_unit\" + 0.005*\"hidden_layer\" + 0.005*\"lstm\" + 0.005*\"proposal\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:31,506 : INFO : topic #1 (0.051): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"submodular\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:31,508 : INFO : topic #2 (0.059): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"singular_value\" + 0.004*\"step_size\" + 0.004*\"sample_complexity\" + 0.004*\"regularization_parameter\" + 0.004*\"recovery\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:31,509 : INFO : topic #3 (0.066): 0.008*\"gaussian_process\" + 0.006*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"sampler\" + 0.003*\"mcmc\" + 0.003*\"covariance_matrix\" + 0.003*\"graphical_model\" + 0.003*\"mixture_model\" + 0.003*\"step_size\"\n",
      "2020-02-27 19:08:31,509 : INFO : topic diff=0.037123, rho=0.229416\n",
      "2020-02-27 19:08:31,517 : INFO : PROGRESS: pass 18, at document #403/403\n",
      "2020-02-27 19:08:31,518 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:32,052 : DEBUG : 403/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:32,055 : INFO : optimized alpha [0.048543457, 0.05107345, 0.059835806, 0.066492535]\n",
      "2020-02-27 19:08:32,056 : DEBUG : updating topics\n",
      "2020-02-27 19:08:32,060 : INFO : topic #0 (0.049): 0.006*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"deep_learning\" + 0.005*\"recurrent_neural\" + 0.005*\"hidden_unit\" + 0.005*\"hidden_layer\" + 0.005*\"lstm\" + 0.005*\"proposal\" + 0.004*\"generative_model\"\n",
      "2020-02-27 19:08:32,061 : INFO : topic #1 (0.051): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"submodular\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:32,062 : INFO : topic #2 (0.060): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.004*\"gradient_descent\" + 0.004*\"singular_value\" + 0.004*\"step_size\" + 0.004*\"regularization_parameter\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:32,063 : INFO : topic #3 (0.066): 0.008*\"gaussian_process\" + 0.006*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"sampler\" + 0.003*\"mcmc\" + 0.003*\"covariance_matrix\" + 0.003*\"graphical_model\" + 0.003*\"mixture_model\" + 0.003*\"gibbs\"\n",
      "2020-02-27 19:08:32,064 : INFO : topic diff=0.034422, rho=0.223607\n",
      "2020-02-27 19:08:32,070 : INFO : PROGRESS: pass 19, at document #403/403\n",
      "2020-02-27 19:08:32,071 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:32,585 : DEBUG : 402/403 documents converged within 400 iterations\n",
      "2020-02-27 19:08:32,588 : INFO : optimized alpha [0.04859063, 0.05141662, 0.06041521, 0.066817276]\n",
      "2020-02-27 19:08:32,589 : DEBUG : updating topics\n",
      "2020-02-27 19:08:32,593 : INFO : topic #0 (0.049): 0.007*\"convolutional\" + 0.005*\"fully_connected\" + 0.005*\"recurrent\" + 0.005*\"deep_learning\" + 0.005*\"recurrent_neural\" + 0.005*\"hidden_unit\" + 0.005*\"hidden_layer\" + 0.005*\"lstm\" + 0.005*\"generative_model\" + 0.004*\"proposal\"\n",
      "2020-02-27 19:08:32,594 : INFO : topic #1 (0.051): 0.012*\"regret\" + 0.007*\"bandit\" + 0.006*\"policy\" + 0.006*\"active_learning\" + 0.005*\"submodular\" + 0.005*\"reward\" + 0.005*\"game\" + 0.005*\"regret_bound\" + 0.005*\"query\" + 0.005*\"item\"\n",
      "2020-02-27 19:08:32,596 : INFO : topic #2 (0.060): 0.006*\"matrix_completion\" + 0.006*\"rank_matrix\" + 0.006*\"convergence_rate\" + 0.005*\"gradient_descent\" + 0.004*\"singular_value\" + 0.004*\"step_size\" + 0.004*\"regularization_parameter\" + 0.004*\"sample_complexity\" + 0.004*\"recovery\" + 0.004*\"strongly_convex\"\n",
      "2020-02-27 19:08:32,597 : INFO : topic #3 (0.067): 0.008*\"gaussian_process\" + 0.006*\"variational_inference\" + 0.004*\"markov_chain\" + 0.004*\"posterior_distribution\" + 0.003*\"sampler\" + 0.003*\"mcmc\" + 0.003*\"covariance_matrix\" + 0.003*\"graphical_model\" + 0.003*\"gibbs\" + 0.003*\"mixture_model\"\n",
      "2020-02-27 19:08:32,598 : INFO : topic diff=0.031994, rho=0.218218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.3 s, sys: 1.42 s, total: 48.8 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 4\n",
    "chunksize = 500 # Size of the doc looked at every pass\n",
    "passes = 20 # Number of passes through documents\n",
    "iterations = 400 # Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "%time model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, \\\n",
    "                       alpha='auto', eta='auto', \\\n",
    "                       iterations=iterations, num_topics=num_topics, \\\n",
    "                       passes=passes, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 1 for Determining Optimal Number of Topics: Topic Coherence\n",
    "\n",
    "Topic Coherence is a measure used to evaluate topic models. Each such generated topic consists of words, and the topic coherence is applied to the top N words from the topic. \n",
    "\n",
    "Topic Coherence measures score a single topic by **measuring the degree of semantic similarity between high scoring words in the topic**. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. \n",
    "\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”\n",
    "\n",
    "Topic Coherence is defined as the average of the pairwise word-similarity scores of the words in the topic.\n",
    "\n",
    "A good model will generate coherent topics, i.e., topics with high topic coherence scores. Good topics are topics that can be described by a short label, therefore this is what the topic coherence measure should capture.\n",
    "\n",
    "\n",
    "Below we display \n",
    "- the average topic coherence and\n",
    "- print the topics in order of topic coherence\n",
    "\n",
    "\n",
    "We use LdaModel's \"top_topics\" method to get the topics with the highest coherence score the coherence for each topic.\n",
    "\n",
    "Note that we use the “Umass” topic coherence measure here (see gensim.models.ldamodel.LdaModel.top_topics())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:32,613 : DEBUG : Setting topics to those of the model: LdaModel(num_terms=6001, num_topics=4, decay=0.5, chunksize=500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.6154.\n",
      "[([(0.006503164, 'convolutional'),\n",
      "   (0.005490133, 'fully_connected'),\n",
      "   (0.0054501276, 'recurrent'),\n",
      "   (0.0052782292, 'deep_learning'),\n",
      "   (0.0052202637, 'recurrent_neural'),\n",
      "   (0.004987433, 'hidden_unit'),\n",
      "   (0.0047173062, 'hidden_layer'),\n",
      "   (0.0046798713, 'lstm'),\n",
      "   (0.0045049815, 'generative_model'),\n",
      "   (0.0044646817, 'proposal'),\n",
      "   (0.004120675, 'convolutional_neural'),\n",
      "   (0.0040228195, 'segmentation'),\n",
      "   (0.0039855647, 'ground_truth'),\n",
      "   (0.003952189, 'pixel'),\n",
      "   (0.0039449367, 'during_training'),\n",
      "   (0.0034225394, 'sentence'),\n",
      "   (0.0032817528, 'convolutional_network'),\n",
      "   (0.003246106, 'document'),\n",
      "   (0.0032047795, 'deep_network'),\n",
      "   (0.003117191, 'embedding')],\n",
      "  -1.120357126950858),\n",
      " ([(0.0063719475, 'matrix_completion'),\n",
      "   (0.0060113417, 'rank_matrix'),\n",
      "   (0.005963978, 'convergence_rate'),\n",
      "   (0.0045467974, 'gradient_descent'),\n",
      "   (0.0044015325, 'singular_value'),\n",
      "   (0.004283363, 'step_size'),\n",
      "   (0.0040224795, 'regularization_parameter'),\n",
      "   (0.0039851526, 'sample_complexity'),\n",
      "   (0.003935671, 'recovery'),\n",
      "   (0.003909557, 'strongly_convex'),\n",
      "   (0.0038108092, 'line_search'),\n",
      "   (0.0036340686, 'logistic_regression'),\n",
      "   (0.0033275979, 'data_set'),\n",
      "   (0.003141177, 'nuclear_norm'),\n",
      "   (0.0030869558, 'covariance_matrix'),\n",
      "   (0.003068857, 'rate_convergence'),\n",
      "   (0.0030534067, 'graphical_model'),\n",
      "   (0.0029906526, 'tensor'),\n",
      "   (0.002848024, 'least_square'),\n",
      "   (0.002757426, 'completion')],\n",
      "  -1.6122747289756179),\n",
      " ([(0.007716729, 'gaussian_process'),\n",
      "   (0.0059054685, 'variational_inference'),\n",
      "   (0.004178529, 'markov_chain'),\n",
      "   (0.003825567, 'posterior_distribution'),\n",
      "   (0.003227254, 'sampler'),\n",
      "   (0.003162447, 'mcmc'),\n",
      "   (0.0031326143, 'covariance_matrix'),\n",
      "   (0.0030444146, 'graphical_model'),\n",
      "   (0.0029404503, 'gibbs'),\n",
      "   (0.0029231263, 'mixture_model'),\n",
      "   (0.0027380185, 'neuron'),\n",
      "   (0.0027244834, 'mean_field'),\n",
      "   (0.0026989677, 'exponential_family'),\n",
      "   (0.0026918694, 'step_size'),\n",
      "   (0.0025910246, 'bayesian_inference'),\n",
      "   (0.0025377276, 'marginal_likelihood'),\n",
      "   (0.00253461, 'gibbs_sampling'),\n",
      "   (0.0025080475, 'gibbs_sampler'),\n",
      "   (0.0024567898, 'moment'),\n",
      "   (0.0024210762, 'embedding')],\n",
      "  -1.7151405232773265),\n",
      " ([(0.011727283, 'regret'),\n",
      "   (0.00674021, 'bandit'),\n",
      "   (0.0062575787, 'policy'),\n",
      "   (0.0062127975, 'active_learning'),\n",
      "   (0.0054041194, 'submodular'),\n",
      "   (0.0051703136, 'reward'),\n",
      "   (0.00501175, 'game'),\n",
      "   (0.0047741598, 'regret_bound'),\n",
      "   (0.0047674584, 'query'),\n",
      "   (0.0046674632, 'item'),\n",
      "   (0.004616366, 'random_walk'),\n",
      "   (0.0045534894, 'agent'),\n",
      "   (0.00427403, 'greedy'),\n",
      "   (0.0042290743, 'round'),\n",
      "   (0.004215338, 'online_learning'),\n",
      "   (0.004210019, 'sample_complexity'),\n",
      "   (0.0041248184, 'vertex'),\n",
      "   (0.0040681413, 'reward_function'),\n",
      "   (0.0039330916, 'time_step'),\n",
      "   (0.0035738095, 'greedy_algorithm')],\n",
      "  -2.0136281168790022)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technique 2 for Determining Optimal Number of Topics: Visualization\n",
    "\n",
    "We use **pyLDAvis** to interpret the topics in a topic model that has been fit to a corpus of text data. \n",
    "\n",
    "It extracts information from a fitted LDA topic model to inform an interactive web-based visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-27 19:08:32,828 : DEBUG : performing inference on a chunk of 403 documents\n",
      "2020-02-27 19:08:33,291 : DEBUG : 403/403 documents converged within 400 iterations\n",
      "/Users/hasan/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el648731124192953041061328652\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el648731124192953041061328652_data = {\"mdsDat\": {\"x\": [-0.13157676174043773, 0.03206465603638612, -0.10332900207031538, 0.20284110777436684], \"y\": [-0.10406079961059644, -0.054059851366719765, 0.14381528140029992, 0.014305369577016423], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [27.028528213500977, 25.891464233398438, 23.653621673583984, 23.4263858795166]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [1223.0, 929.0, 703.0, 763.0, 676.0, 724.0, 673.0, 685.0, 579.0, 544.0, 545.0, 594.0, 600.0, 499.0, 484.0, 550.0, 804.0, 502.0, 548.0, 483.0, 611.0, 425.0, 918.0, 429.0, 410.0, 585.0, 631.0, 586.0, 507.0, 444.0, 291.5421447753906, 183.4270477294922, 759.0704956054688, 123.3383560180664, 319.1951599121094, 120.28668212890625, 160.9886474609375, 233.50169372558594, 221.3189697265625, 80.33177185058594, 77.29872131347656, 81.25823974609375, 81.22399139404297, 122.79104614257812, 716.1126098632812, 60.26906967163086, 84.94264221191406, 52.16987228393555, 44.2867317199707, 65.87525939941406, 56.96076202392578, 38.2314453125, 251.0577850341797, 374.19873046875, 41.12010955810547, 65.56585693359375, 39.13755798339844, 182.94985961914062, 33.22878646850586, 53.6953125, 169.6317138671875, 146.20834350585938, 257.7119140625, 151.4625244140625, 264.2269287109375, 479.18560791015625, 156.26492309570312, 306.21734619140625, 468.8443603515625, 465.7335205078125, 328.4836730957031, 453.969970703125, 524.3410034179688, 365.5834655761719, 162.94073486328125, 141.3600616455078, 176.2570037841797, 286.13922119140625, 296.2237548828125, 273.4127502441406, 710.4703369140625, 325.0019226074219, 327.3341979980469, 266.7593994140625, 541.64599609375, 432.9154052734375, 510.26385498046875, 339.2763366699219, 297.98211669921875, 474.73895263671875, 305.0758972167969, 396.406494140625, 367.7395324707031, 356.2672424316406, 363.7429504394531, 311.99346923828125, 310.4457702636719, 304.9753112792969, 142.3451385498047, 86.17753601074219, 88.08746337890625, 88.9491195678711, 64.4337387084961, 74.19004821777344, 212.5326690673828, 59.439910888671875, 105.23455810546875, 53.542110443115234, 54.4136848449707, 50.5175895690918, 61.17946243286133, 110.66796875, 215.3656768798828, 29.85943603515625, 58.49675369262695, 159.09512329101562, 218.72694396972656, 23.873170852661133, 38.14119338989258, 37.105953216552734, 189.17709350585938, 51.289642333984375, 36.98311996459961, 132.8577117919922, 71.09606170654297, 43.51325607299805, 368.2792663574219, 16.96697235107422, 880.5973510742188, 360.8837890625, 172.25332641601562, 333.5736389160156, 108.55238342285156, 159.27633666992188, 286.2067565917969, 219.1886749267578, 436.55596923828125, 289.5937194824219, 310.9054260253906, 245.0600128173828, 673.9047241210938, 295.67572021484375, 245.04595947265625, 116.55168151855469, 161.42977905273438, 335.5505676269531, 239.68003845214844, 186.14212036132812, 186.62332153320312, 249.45326232910156, 189.6874237060547, 476.8343811035156, 280.35748291015625, 307.9936828613281, 312.4499816894531, 289.2379455566406, 266.9671325683594, 357.47943115234375, 347.41448974609375, 232.6878662109375, 276.281982421875, 307.18365478515625, 271.0368347167969, 245.67796325683594, 232.76710510253906, 221.44647216796875, 1222.5948486328125, 702.681640625, 311.8151550292969, 279.0845642089844, 497.7165832519531, 424.1126403808594, 168.88194274902344, 367.34075927734375, 125.25991821289062, 123.24829864501953, 113.33348846435547, 119.20246887207031, 105.39752197265625, 86.53998565673828, 84.54608154296875, 80.59860229492188, 78.61528015136719, 95.27786254882812, 71.68708038330078, 89.32209014892578, 67.711669921875, 89.28561401367188, 539.0164794921875, 65.64363861083984, 130.28713989257812, 60.676231384277344, 261.1259460449219, 66.44244384765625, 72.2985610961914, 283.30322265625, 474.71124267578125, 173.93829345703125, 99.6204833984375, 647.69775390625, 652.3662719726562, 173.74859619140625, 522.4859008789062, 563.3912963867188, 154.888671875, 369.39227294921875, 263.7337341308594, 312.0252990722656, 264.8014221191406, 372.57745361328125, 440.8902587890625, 486.59326171875, 237.80699157714844, 214.07571411132812, 270.77801513671875, 445.5769958496094, 481.2662353515625, 497.0179748535156, 439.45819091796875, 270.9323425292969, 430.0213317871094, 326.3161926269531, 410.0334167480469, 438.9036865234375, 301.1687927246094, 282.92877197265625, 326.7285461425781, 294.5888366699219, 483.1997375488281, 260.6630859375, 203.54127502441406, 338.8431091308594, 159.15774536132812, 147.6446075439453, 407.3172607421875, 113.03424072265625, 119.73739624023438, 671.4558715820312, 102.45589447021484, 219.20347595214844, 200.04928588867188, 98.4966049194336, 425.4623718261719, 92.72169494628906, 86.02694702148438, 85.06932830810547, 99.38868713378906, 538.99560546875, 109.88737487792969, 81.18932342529297, 81.19070434570312, 353.3794250488281, 82.12513732910156, 124.08372497558594, 81.07342529296875, 116.29438781738281, 69.57489776611328, 85.76045989990234, 214.22247314453125, 196.95179748535156, 330.89556884765625, 246.1346893310547, 562.7291870117188, 487.06494140625, 233.3056640625, 203.44677734375, 566.8598022460938, 166.078125, 204.1178741455078, 514.9556884765625, 169.97047424316406, 163.59042358398438, 415.35870361328125, 544.9805908203125, 187.85092163085938, 316.353515625, 408.0660705566406, 214.9902801513672, 299.64642333984375, 199.3730926513672, 460.9812927246094, 269.1062927246094, 295.8661804199219, 465.1422424316406, 319.3604736328125, 284.13720703125, 266.88726806640625, 239.488037109375, 411.51214599609375, 335.16253662109375, 287.2726135253906, 321.85198974609375, 250.19004821777344], \"Term\": [\"regret\", \"gaussian_process\", \"bandit\", \"matrix_completion\", \"convolutional\", \"rank_matrix\", \"active_learning\", \"policy\", \"recurrent\", \"recurrent_neural\", \"reward\", \"fully_connected\", \"submodular\", \"regret_bound\", \"lstm\", \"game\", \"variational_inference\", \"hidden_layer\", \"hidden_unit\", \"agent\", \"deep_learning\", \"reward_function\", \"sample_complexity\", \"convolutional_neural\", \"during_training\", \"singular_value\", \"random_walk\", \"proposal\", \"regularization_parameter\", \"segmentation\", \"primal_dual\", \"exact_recovery\", \"matrix_completion\", \"linear_measurement\", \"lasso\", \"group_lasso\", \"dual_variable\", \"convex_relaxation\", \"strong_convexity\", \"dantzig_selector\", \"incoherence\", \"restricted_strong\", \"foundation_computational\", \"statistical_guarantee\", \"rank_matrix\", \"recovery_guarantee\", \"decomposable\", \"nonsmooth\", \"dantzig\", \"stochastic_dual\", \"current_iterate\", \"vershynin\", \"linear_convergence\", \"nuclear_norm\", \"lasso_journal\", \"accelerated_gradient\", \"cande\", \"alternating_minimization\", \"candes\", \"accelerated_proximal\", \"wolfe\", \"nuclear\", \"primal\", \"iteration_complexity\", \"compressed_sensing\", \"regularization_parameter\", \"nonconvex\", \"coordinate_descent\", \"recovery\", \"strongly_convex\", \"completion\", \"line_search\", \"singular_value\", \"rate_convergence\", \"polytope\", \"sparse_recovery\", \"block_coordinate\", \"relaxation\", \"rank_approximation\", \"proximal\", \"convergence_rate\", \"empirical_risk\", \"estimation_error\", \"singular\", \"gradient_descent\", \"logistic_regression\", \"step_size\", \"least_square\", \"subspace\", \"sample_complexity\", \"support_vector\", \"data_set\", \"covariance_matrix\", \"tensor\", \"graphical_model\", \"probability_least\", \"running_time\", \"sample_size\", \"hamiltonian_monte\", \"langevin_dynamic\", \"posterior_predictive\", \"poisson_process\", \"langevin\", \"metropolis_hastings\", \"lifted\", \"squared_exponential\", \"hamiltonian\", \"covariance_function\", \"quadrature\", \"welling_bayesian\", \"gaussian_approximation\", \"bayesian_nonparametric\", \"bayesian_optimization\", \"stochastic_gradient_langevin_dynamic\", \"cluster_assignment\", \"mixture_gaussians\", \"posterior_mean\", \"titsias\", \"taylor_expansion\", \"mcmc_method\", \"point_process\", \"metropolis\", \"gretton\", \"dirichlet_process\", \"markov_chain_monte_carlo\", \"black_variational\", \"sampler\", \"mackay\", \"gaussian_process\", \"mcmc\", \"disease\", \"mixture_model\", \"firing\", \"predictive_distribution\", \"gibbs_sampler\", \"asynchronous\", \"posterior_distribution\", \"marginal_likelihood\", \"mean_field\", \"probability_measure\", \"variational_inference\", \"bayesian_inference\", \"dimensionality_reduction\", \"auxiliary_variable\", \"true_posterior\", \"gibbs\", \"manifold\", \"activity\", \"particle\", \"stationary_distribution\", \"dirichlet\", \"markov_chain\", \"moment\", \"exponential_family\", \"neuron\", \"gibbs_sampling\", \"population\", \"covariance_matrix\", \"graphical_model\", \"cell\", \"embedding\", \"step_size\", \"tensor\", \"maximum_likelihood\", \"first_order\", \"ground_truth\", \"regret\", \"bandit\", \"multi_armed\", \"bandit_problem\", \"regret_bound\", \"reward_function\", \"decision_maker\", \"player\", \"expected_reward\", \"maker\", \"time_horizon\", \"bandit_feedback\", \"bandit_setting\", \"cumulative_regret\", \"welfare\", \"upper_confidence\", \"mdps\", \"exploration_exploitation\", \"regret_minimization\", \"bianchi\", \"bubeck\", \"cesa\", \"reward\", \"weighted_majority\", \"submodular_maximization\", \"robert_schapire\", \"private\", \"disagreement\", \"regret_regret\", \"market\", \"agent\", \"arm\", \"expected_cost\", \"active_learning\", \"policy\", \"armed\", \"game\", \"submodular\", \"horizon\", \"submodular_function\", \"decision_making\", \"causal\", \"privacy\", \"greedy_algorithm\", \"round\", \"item\", \"price\", \"each_round\", \"learner\", \"greedy\", \"random_walk\", \"query\", \"online_learning\", \"walk\", \"vertex\", \"reinforcement_learning\", \"time_step\", \"sample_complexity\", \"mechanism\", \"confidence\", \"markov_chain\", \"probability_least\", \"lstm\", \"object_detection\", \"convolutional_layer\", \"convolutional_network\", \"semantic_segmentation\", \"object_recognition\", \"during_training\", \"pooling_layer\", \"autoencoder\", \"convolutional\", \"very_deep\", \"recurrent_network\", \"machine_translation\", \"lstms\", \"convolutional_neural\", \"lstm_lstm\", \"parsing\", \"rnns\", \"cnns\", \"recurrent_neural\", \"visual_recognition\", \"alex_graf\", \"image_caption\", \"sentence\", \"ilya_sutskever\", \"encoder_decoder\", \"input_image\", \"sutskever\", \"recurrent_convolutional\", \"iclr\", \"encoder\", \"stack\", \"deep_network\", \"deep_convolutional\", \"recurrent\", \"hidden_layer\", \"speech_recognition\", \"dropout\", \"fully_connected\", \"sequence_sequence\", \"texture\", \"hidden_unit\", \"data_augmentation\", \"decoder\", \"segmentation\", \"deep_learning\", \"patch\", \"deep_neural\", \"pixel\", \"pooling\", \"multi_label\", \"yoshua_bengio\", \"proposal\", \"feature_map\", \"hidden_state\", \"generative_model\", \"semi_supervised\", \"spatial\", \"frame\", \"unlabeled_data\", \"ground_truth\", \"document\", \"topic_model\", \"embedding\", \"answer\"], \"Total\": [1223.0, 929.0, 703.0, 763.0, 676.0, 724.0, 673.0, 685.0, 579.0, 544.0, 545.0, 594.0, 600.0, 499.0, 484.0, 550.0, 804.0, 502.0, 548.0, 483.0, 611.0, 425.0, 918.0, 429.0, 410.0, 585.0, 631.0, 586.0, 507.0, 444.0, 292.3908386230469, 184.23390197753906, 763.0228271484375, 124.14948272705078, 321.41217041015625, 121.14262390136719, 162.19065856933594, 235.28240966796875, 223.2722930908203, 81.0879898071289, 78.0826644897461, 82.0867919921875, 82.08416748046875, 124.13701629638672, 724.7394409179688, 61.052276611328125, 86.05028533935547, 53.0400390625, 45.036075592041016, 67.05470275878906, 58.04771041870117, 39.02362823486328, 256.27471923828125, 382.4128723144531, 42.02460479736328, 67.03421020507812, 40.022579193115234, 187.1073760986328, 34.01604461669922, 55.02341842651367, 174.1726837158203, 150.13137817382812, 266.2281494140625, 156.1316680908203, 274.0182189941406, 507.2755126953125, 162.10877990722656, 322.2327880859375, 504.2084655761719, 505.3147888183594, 351.9753723144531, 495.9759826660156, 585.8912353515625, 402.0682678222656, 172.0946502685547, 148.11764526367188, 188.1013641357422, 327.9399108886719, 341.7572937011719, 312.8818054199219, 969.4115600585938, 393.8458251953125, 400.7668762207031, 314.7467041015625, 790.0478515625, 639.8320922851562, 843.5293579101562, 480.086181640625, 406.13238525390625, 918.2904663085938, 425.37420654296875, 775.5684814453125, 734.0511474609375, 685.2084350585938, 759.053955078125, 614.105712890625, 700.8024291992188, 650.7879638671875, 143.2985382080078, 86.95777893066406, 88.93319702148438, 89.92436981201172, 65.21288299560547, 75.09709167480469, 215.4417724609375, 60.273189544677734, 106.71813201904297, 54.34243392944336, 55.327667236328125, 51.37081527709961, 62.22280502319336, 112.6307601928711, 220.36801147460938, 30.618907928466797, 60.239383697509766, 164.07382202148438, 226.17262268066406, 24.6895694732666, 39.50908279418945, 38.50665283203125, 196.6886444091797, 53.34326934814453, 38.51593780517578, 138.37258911132812, 74.06873321533203, 45.415672302246094, 385.0569763183594, 17.770565032958984, 929.2549438476562, 381.0369567871094, 180.8934783935547, 353.6395263671875, 114.52760314941406, 169.79513549804688, 311.7742919921875, 237.10507202148438, 485.1358947753906, 321.89984130859375, 347.0448913574219, 273.9673767089844, 804.1585693359375, 340.3885192871094, 282.3006591796875, 125.46086883544922, 183.2978515625, 434.04449462890625, 296.4991760253906, 222.64926147460938, 223.62353515625, 325.43896484375, 232.4096221923828, 817.4751586914062, 406.5187072753906, 470.40899658203125, 493.84552001953125, 467.1190490722656, 418.41424560546875, 734.0511474609375, 759.053955078125, 374.82781982421875, 622.8978881835938, 843.5293579101562, 685.2084350585938, 515.19384765625, 489.93597412109375, 792.9422607421875, 1223.7744140625, 703.68798828125, 312.6313781738281, 279.8771667480469, 499.21142578125, 425.7740783691406, 169.70364379882812, 369.1588439941406, 126.03363037109375, 124.04631805419922, 114.12007141113281, 120.07691192626953, 106.17903900146484, 87.32080078125, 85.33654022216797, 81.36592102050781, 79.3843002319336, 96.24519348144531, 72.43621063232422, 90.29424285888672, 68.4652328491211, 90.2945556640625, 545.7131958007812, 66.47380065917969, 131.96737670898438, 61.51165008544922, 264.9792785644531, 67.46033477783203, 73.41686248779297, 287.7214050292969, 483.1417541503906, 177.54917907714844, 101.21827697753906, 673.7880249023438, 685.0402221679688, 178.6304168701172, 550.10595703125, 600.7473754882812, 159.68821716308594, 398.2171936035156, 281.63189697265625, 337.17413330078125, 285.96856689453125, 421.208251953125, 517.598388671875, 605.539306640625, 266.0520324707031, 236.25025939941406, 313.98529052734375, 571.8994750976562, 631.4910888671875, 662.8937377929688, 572.1901245117188, 329.0988464355469, 669.813720703125, 445.4804382324219, 678.84521484375, 918.2904663085938, 464.6846923828125, 372.8512268066406, 817.4751586914062, 614.105712890625, 484.3894958496094, 261.4912109375, 204.56893920898438, 340.6326904296875, 160.185302734375, 148.60374450683594, 410.12835693359375, 113.866455078125, 120.619873046875, 676.4843139648438, 103.25181579589844, 220.9844970703125, 201.68844604492188, 99.39472198486328, 429.4615478515625, 93.6048812866211, 86.84870147705078, 85.88458251953125, 100.3613052368164, 544.3148803710938, 110.97383117675781, 82.02359008789062, 82.02598571777344, 357.0684509277344, 82.9877700805664, 125.45729064941406, 82.02766418457031, 117.73405456542969, 70.44824981689453, 86.8502426147461, 217.1495819091797, 199.7649383544922, 337.8536682128906, 250.9649200439453, 579.302001953125, 502.0747375488281, 238.4401092529297, 207.5225830078125, 594.100341796875, 169.9174041748047, 210.4582061767578, 548.8383178710938, 174.73265075683594, 167.96681213378906, 444.8100280761719, 611.5609741210938, 195.0624237060547, 342.1640930175781, 451.6576843261719, 228.04714965820312, 334.91192626953125, 209.67393493652344, 586.723876953125, 316.62445068359375, 382.20098876953125, 796.331298828125, 441.92120361328125, 371.6631774902344, 339.4072265625, 277.91290283203125, 792.9422607421875, 530.9894409179688, 411.0550842285156, 622.8978881835938, 375.018310546875], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.305400013923645, 1.3039000034332275, 1.3030999898910522, 1.3016999959945679, 1.3013999462127686, 1.301200032234192, 1.3007999658584595, 1.3006999492645264, 1.2994999885559082, 1.2989000082015991, 1.298200011253357, 1.2980999946594238, 1.297700047492981, 1.2973999977111816, 1.2963000535964966, 1.2954000234603882, 1.295300006866455, 1.291700005531311, 1.2914999723434448, 1.2905000448226929, 1.2893999814987183, 1.2877999544143677, 1.2877000570297241, 1.2865999937057495, 1.2864999771118164, 1.2861000299453735, 1.2858999967575073, 1.2857999801635742, 1.2848999500274658, 1.2838000059127808, 1.2819000482559204, 1.2818000316619873, 1.2757999897003174, 1.277899980545044, 1.2719000577926636, 1.2512999773025513, 1.2716000080108643, 1.2573000192642212, 1.2355999946594238, 1.226699948310852, 1.2391999959945679, 1.2197999954223633, 1.1972999572753906, 1.2131999731063843, 1.253600001335144, 1.2616000175476074, 1.2431999444961548, 1.1719000339508057, 1.1653000116348267, 1.1734000444412231, 0.9975000023841858, 1.1160999536514282, 1.1059000492095947, 1.142899990081787, 0.9308000206947327, 0.9175999760627747, 0.8055999875068665, 0.9610999822616577, 0.9986000061035156, 0.6485000252723694, 0.9758999943733215, 0.6370999813079834, 0.6171000003814697, 0.65420001745224, 0.572700023651123, 0.6310999989509583, 0.49410000443458557, 0.5503000020980835, 1.344599962234497, 1.3422000408172607, 1.3416999578475952, 1.340399980545044, 1.3392000198364258, 1.3391000032424927, 1.3377000093460083, 1.3372999429702759, 1.3372999429702759, 1.336400032043457, 1.3345999717712402, 1.3344999551773071, 1.3343000411987305, 1.3336999416351318, 1.3282999992370605, 1.3260999917984009, 1.3219000101089478, 1.3203999996185303, 1.3178000450134277, 1.3176000118255615, 1.315999984741211, 1.3142000436782837, 1.3122999668121338, 1.312000036239624, 1.3106000423431396, 1.3106000423431396, 1.3102999925613403, 1.308500051498413, 1.3066999912261963, 1.3049999475479126, 1.2975000143051147, 1.2969000339508057, 1.302299976348877, 1.292799949645996, 1.297700047492981, 1.2872999906539917, 1.2656999826431274, 1.2726999521255493, 1.2457000017166138, 1.2454999685287476, 1.2412999868392944, 1.239799976348877, 1.1744999885559082, 1.2103999853134155, 1.2096999883651733, 1.2776000499725342, 1.2242000102996826, 1.0938999652862549, 1.1384999752044678, 1.1721999645233154, 1.1704000234603882, 1.0853999853134155, 1.1481000185012817, 0.8122000098228455, 0.9797000288963318, 0.9276999831199646, 0.8934999704360962, 0.8719000220298767, 0.9018999934196472, 0.6317999958992004, 0.5697000026702881, 0.8744999766349792, 0.5382999777793884, 0.3411000072956085, 0.423799991607666, 0.6107000112533569, 0.6069999933242798, 0.07569999992847443, 1.4407000541687012, 1.4401999711990356, 1.4390000104904175, 1.4387999773025513, 1.4386999607086182, 1.4377000331878662, 1.4368000030517578, 1.4366999864578247, 1.4355000257492065, 1.4351999759674072, 1.4347000122070312, 1.4342999458312988, 1.4342999458312988, 1.4327000379562378, 1.4322999715805054, 1.4321999549865723, 1.4319000244140625, 1.4315999746322632, 1.4313000440597534, 1.430799961090088, 1.4306000471115112, 1.430400013923645, 1.4292999505996704, 1.4291000366210938, 1.4287999868392944, 1.4279999732971191, 1.4270000457763672, 1.4264999628067017, 1.426300048828125, 1.426200032234192, 1.4241000413894653, 1.4211000204086304, 1.4256999492645264, 1.4021999835968018, 1.392799973487854, 1.4139000177383423, 1.3901000022888184, 1.377500057220459, 1.4111000299453735, 1.3665000200271606, 1.3760000467300415, 1.3640999794006348, 1.364799976348877, 1.319000005722046, 1.2812999486923218, 1.2230000495910645, 1.3293999433517456, 1.3430999517440796, 1.2935999631881714, 1.1921000480651855, 1.1699999570846558, 1.1536999940872192, 1.1777000427246094, 1.2472000122070312, 0.9984999895095825, 1.1303999423980713, 0.9375, 0.7034000158309937, 1.0080000162124634, 1.1656999588012695, 0.5246000289916992, 0.707099974155426, 1.448799967765808, 1.448099970817566, 1.4463000297546387, 1.4459999799728394, 1.4449000358581543, 1.4448000192642212, 1.4443999528884888, 1.444000005722046, 1.444000005722046, 1.4437999725341797, 1.443600058555603, 1.4431999921798706, 1.4430999755859375, 1.442199945449829, 1.4420000314712524, 1.4417999982833862, 1.4417999982833862, 1.4417999982833862, 1.44159996509552, 1.441499948501587, 1.441499948501587, 1.441100001335144, 1.441100001335144, 1.4408999681472778, 1.4408999681472778, 1.4402999877929688, 1.4395999908447266, 1.4390000104904175, 1.4387999773025513, 1.4386999607086182, 1.4377000331878662, 1.4371000528335571, 1.4305000305175781, 1.4319000244140625, 1.4222999811172485, 1.4210000038146973, 1.4294999837875366, 1.43149995803833, 1.4043999910354614, 1.4285000562667847, 1.420699954032898, 1.3875999450683594, 1.423699975013733, 1.4249000549316406, 1.3827999830245972, 1.3359999656677246, 1.413599967956543, 1.3729000091552734, 1.3497999906539917, 1.392300009727478, 1.340000033378601, 1.4009000062942505, 1.2101000547409058, 1.288699984550476, 1.1952999830245972, 0.9136000275611877, 1.1265000104904175, 1.182800054550171, 1.2108999490737915, 1.3025000095367432, 0.7954000234603882, 0.9911999702453613, 1.093000054359436, 0.7910000085830688, 1.0465999841690063], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.012800216674805, -6.476099967956543, -5.055799961090088, -6.873000144958496, -5.922100067138672, -6.898099899291992, -6.606599807739258, -6.234799861907959, -6.288300037384033, -7.301799774169922, -7.3403000831604, -7.290299892425537, -7.2906999588012695, -6.877500057220459, -5.114099979400635, -7.589099884033203, -7.245999813079834, -7.733399868011475, -7.897299766540527, -7.500199794769287, -7.645599842071533, -8.044300079345703, -6.162300109863281, -5.763199806213379, -7.971399784088135, -7.504899978637695, -8.020899772644043, -6.478700160980225, -8.184499740600586, -7.704599857330322, -6.554299831390381, -6.702899932861328, -6.136099815368652, -6.667600154876709, -6.111100196838379, -5.515900135040283, -6.63640022277832, -5.963600158691406, -5.537700176239014, -5.544300079345703, -5.893499851226807, -5.569900035858154, -5.42579984664917, -5.786399841308594, -6.594600200653076, -6.736599922180176, -6.515999794006348, -6.031499862670898, -5.996799945831299, -6.077000141143799, -5.122000217437744, -5.904099941253662, -5.896999835968018, -6.101600170135498, -5.3933000564575195, -5.617400169372559, -5.453000068664551, -5.861100196838379, -5.990900039672852, -5.525199890136719, -5.967400074005127, -5.70550012588501, -5.780600070953369, -5.812300205230713, -5.791500091552734, -5.945000171661377, -5.949900150299072, -5.967700004577637, -6.686699867248535, -7.188600063323975, -7.166600227355957, -7.156899929046631, -7.479300022125244, -7.3383002281188965, -6.285900115966797, -7.559999942779541, -6.988800048828125, -7.6645002365112305, -7.648399829864502, -7.722599983215332, -7.531199932098389, -6.938399791717529, -6.272600173950195, -8.248499870300293, -7.576000213623047, -6.575500011444092, -6.2571001052856445, -8.472200393676758, -8.003700256347656, -8.031200408935547, -6.402299880981445, -7.707499980926514, -8.034500122070312, -6.75570011138916, -7.380899906158447, -7.8719000816345215, -5.736100196838379, -8.813699722290039, -4.8643999099731445, -5.756400108337402, -6.495999813079834, -5.835100173950195, -6.957699775695801, -6.5742998123168945, -5.98829984664917, -6.255000114440918, -5.565999984741211, -5.976500034332275, -5.9054999351501465, -6.143499851226807, -5.131899833679199, -5.955699920654297, -6.143499851226807, -6.886600017547607, -6.5609002113342285, -5.82919979095459, -6.1656999588012695, -6.418499946594238, -6.415900230407715, -6.125699996948242, -6.399600028991699, -5.477799892425537, -6.008900165557861, -5.914899826049805, -5.9004998207092285, -5.977700233459473, -6.057799816131592, -5.765900135040283, -5.794400215148926, -6.195300102233887, -6.023499965667725, -5.917500019073486, -6.042699813842773, -6.140900135040283, -6.194900035858154, -6.244800090789795, -4.445799827575684, -4.99970006942749, -5.81220006942749, -5.923099994659424, -5.3445000648498535, -5.5046000480651855, -6.4253997802734375, -5.6483001708984375, -6.7241997718811035, -6.7403998374938965, -6.82420015335083, -6.77370023727417, -6.8968000411987305, -7.093999862670898, -7.117300033569336, -7.16510009765625, -7.190000057220459, -6.997799873352051, -7.282299995422363, -7.062300205230713, -7.339300155639648, -7.062699794769287, -5.264800071716309, -7.370299816131592, -6.684800148010254, -7.448999881744385, -5.98960018157959, -7.3582000732421875, -7.273799896240234, -5.908100128173828, -5.391900062561035, -6.395899772644043, -6.953199863433838, -5.081099987030029, -5.073999881744385, -6.396999835968018, -5.296000003814697, -5.220600128173828, -6.511899948120117, -5.6427001953125, -5.979599952697754, -5.811500072479248, -5.975599765777588, -5.634099960327148, -5.465799808502197, -5.367099761962891, -6.083099842071533, -6.188199996948242, -5.9532999992370605, -5.4552001953125, -5.3780999183654785, -5.345900058746338, -5.468999862670898, -5.952700138092041, -5.490699768066406, -5.76669979095459, -5.538300037384033, -5.470300197601318, -5.84689998626709, -5.90939998626709, -5.765399932861328, -5.86899995803833, -5.364500045776367, -5.9816999435424805, -6.229000091552734, -5.719399929046631, -6.474999904632568, -6.550099849700928, -5.535299777984619, -6.817200183868408, -6.7596001625061035, -5.0355000495910645, -6.915500164031982, -6.154900074005127, -6.246399879455566, -6.954899787902832, -5.491700172424316, -7.0152997970581055, -7.0903000831604, -7.101399898529053, -6.945899963378906, -5.255199909210205, -6.8454999923706055, -7.148099899291992, -7.148099899291992, -5.6774001121521, -7.13670015335083, -6.723999977111816, -7.149600028991699, -6.78879976272583, -7.302499771118164, -7.093400001525879, -6.1778998374938965, -6.26200008392334, -5.743100166320801, -6.039000034332275, -5.212100028991699, -5.356500148773193, -6.092599868774414, -6.229499816894531, -5.204800128936768, -6.432499885559082, -6.226200103759766, -5.30079984664917, -6.409299850463867, -6.447500228881836, -5.5157999992370605, -5.244200229644775, -6.309299945831299, -5.788099765777588, -5.5335001945495605, -6.174300193786621, -5.842299938201904, -6.24970006942749, -5.411600112915039, -5.94980001449585, -5.855000019073486, -5.402599811553955, -5.778600215911865, -5.895500183105469, -5.958099842071533, -6.066400051116943, -5.525100231170654, -5.730299949645996, -5.884500026702881, -5.7708001136779785, -6.02269983291626]}, \"token.table\": {\"Topic\": [1, 4, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 4, 1, 2, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 1, 2, 3, 4, 4, 1, 2, 4, 3, 3, 3, 3, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 3, 2, 4, 1, 2, 3, 3, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 4, 4, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 2, 4, 4, 2, 4, 1, 2, 4, 1, 2, 3, 2, 1, 2, 3, 4, 3, 1, 2, 1, 1, 2, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 2, 4, 1, 3, 2, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 2, 4, 1, 2, 3, 1, 1, 3, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 2, 2, 4, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 2, 4, 4, 4, 1, 4, 1, 2, 3, 4, 1, 2, 2, 2, 1, 2, 3, 1, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 1, 2, 3, 4, 3, 4, 4, 4, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 1, 2, 3, 4, 2, 3, 4, 2, 4, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 2, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 1, 2, 1, 2, 3, 4, 4, 1, 2, 3, 4, 4, 2, 3, 4, 2, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 2, 3, 4, 4, 1, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 2, 1, 2, 3, 4, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 2, 4, 2, 3, 4, 3, 2, 3, 3, 2, 3, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 1, 3, 4, 1, 3, 4, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 3, 4, 1, 4, 1, 2, 4, 1, 2, 4, 1, 3, 1, 2, 3, 4, 3, 4, 2, 1, 2, 4, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 2, 3, 1, 2, 3, 4, 2, 4, 3, 2, 3, 4, 2, 2, 4, 2, 4, 2, 3, 4, 3, 1, 2, 4, 1, 1, 2, 3, 4, 4, 2, 4, 1, 2, 3, 4, 3, 3, 2, 1, 2, 3, 1, 2, 4], \"Freq\": [0.9845719337463379, 0.01491775643080473, 0.9814003109931946, 0.018174080178141594, 0.002968292683362961, 0.03561951220035553, 0.9617267847061157, 0.0014841463416814804, 0.008982738479971886, 0.8353946208953857, 0.02245684526860714, 0.13474106788635254, 0.0020697859581559896, 0.9831483364105225, 0.014488501474261284, 0.9875207543373108, 0.9780480265617371, 0.005344524513930082, 0.01603357493877411, 0.039998047053813934, 0.01333268266171217, 0.27998632192611694, 0.6666341423988342, 0.9800101518630981, 0.016896726563572884, 0.01679445244371891, 0.005598150659352541, 0.9740782380104065, 0.004217539448291063, 0.9236411452293396, 0.054828014224767685, 0.02108769677579403, 0.9948609471321106, 0.039853062480688095, 0.9325616955757141, 0.031882449984550476, 0.9990223050117493, 0.9910314679145813, 0.9968658685684204, 0.9888957738876343, 0.00587563868612051, 0.8695945739746094, 0.04994292929768562, 0.07932112365961075, 0.9855211973190308, 0.00887856911867857, 0.00887856911867857, 0.004537863656878471, 0.9756407141685486, 0.013613590970635414, 0.004537863656878471, 0.9856663942337036, 0.968828558921814, 0.022018831223249435, 0.9356657266616821, 0.02126513049006462, 0.03721397742629051, 0.9932048320770264, 0.9744499325752258, 0.970130443572998, 0.020760785788297653, 0.02669243887066841, 0.9253379106521606, 0.02669243887066841, 0.024011025205254555, 0.6216187477111816, 0.13339458405971527, 0.22143501043319702, 0.9856629967689514, 0.9628252387046814, 0.016600435599684715, 0.9864359498023987, 0.9318833947181702, 0.03693440183997154, 0.008523323573172092, 0.019887754693627357, 0.9634395837783813, 0.0036493923980742693, 0.032844532281160355, 0.1180095374584198, 0.07241494208574295, 0.7590158581733704, 0.0536406971514225, 0.732403039932251, 0.14854371547698975, 0.11759711056947708, 0.0010315536055713892, 0.9945495128631592, 0.004250211641192436, 0.004250211641192436, 0.0059129237197339535, 0.99189293384552, 0.9972188472747803, 0.0029357136227190495, 0.995206892490387, 0.002328497124835849, 0.004656994249671698, 0.9896113276481628, 0.9496240615844727, 0.034136813133955, 0.015516732819378376, 0.9936985969543457, 0.5013274550437927, 0.4863421320915222, 0.004086908884346485, 0.00817381776869297, 0.996326208114624, 0.9819508790969849, 0.017227208241820335, 0.976994514465332, 0.9865825772285461, 0.022892115637660027, 0.9729148745536804, 0.5105932354927063, 0.18051275610923767, 0.10701827704906464, 0.20114277303218842, 0.9958536624908447, 0.007101468276232481, 0.03195660933852196, 0.937393844127655, 0.021304404363036156, 0.023814227432012558, 0.9763833284378052, 0.9877945184707642, 0.011621112003922462, 0.01593848317861557, 0.9802166819572449, 0.026162559166550636, 0.07685251533985138, 0.006540639791637659, 0.8911621570587158, 0.0177591685205698, 0.9797140955924988, 0.0029225742910057306, 0.06429663300514221, 0.008767723105847836, 0.9235334992408752, 0.05313483998179436, 0.8678690195083618, 0.07793109863996506, 0.021513739600777626, 0.8175221085548401, 0.008605496026575565, 0.15489892661571503, 0.02890745922923088, 0.9611729979515076, 0.00722686480730772, 0.9783526659011841, 0.027640575543045998, 0.9508358240127563, 0.016584346070885658, 0.005528115201741457, 0.06591468304395676, 0.263658732175827, 0.04143208637833595, 0.6308976411819458, 0.004818752873688936, 0.009637505747377872, 0.009637505747377872, 0.9782068133354187, 0.9926589131355286, 0.006165583152323961, 0.00487652188166976, 0.00243826094083488, 0.9923722743988037, 0.07619038969278336, 0.9058191180229187, 0.012698398903012276, 0.017659395933151245, 0.4430902898311615, 0.02087019383907318, 0.5169386863708496, 0.8251960277557373, 0.005078129470348358, 0.16503919661045074, 0.005078129470348358, 0.00921024102717638, 0.9854958057403564, 0.007970839738845825, 0.9883841872215271, 0.8159356713294983, 0.059885188937187195, 0.12476080656051636, 0.9933025240898132, 0.009879638440907001, 0.987963855266571, 0.9917987585067749, 0.9870622754096985, 0.1764422059059143, 0.6547493934631348, 0.13605181872844696, 0.03188714385032654, 0.003158315783366561, 0.1358075737953186, 0.00947494711726904, 0.8495869636535645, 0.9517356157302856, 0.008731519803404808, 0.04365759715437889, 0.440873920917511, 0.4755723476409912, 0.06327357143163681, 0.020410830155014992, 0.9867920279502869, 0.20329561829566956, 0.008838939480483532, 0.7866656184196472, 0.0016832173569127917, 0.01178252138197422, 0.03366434574127197, 0.9543842077255249, 0.0018178316531702876, 0.0036356633063405752, 0.9489080905914307, 0.04544578865170479, 0.9803479313850403, 0.010761309415102005, 0.9480713605880737, 0.03981684520840645, 0.0021522617898881435, 0.10046070069074631, 0.26873236894607544, 0.0477188341319561, 0.5839278101921082, 0.006911733653396368, 0.774114191532135, 0.041470400989055634, 0.17970508337020874, 0.917330265045166, 0.009622345678508282, 0.07056386768817902, 0.6186859607696533, 0.002140781842172146, 0.3789183795452118, 0.6860343813896179, 0.07974200695753098, 0.07974200695753098, 0.15568676590919495, 0.4795443117618561, 0.457148015499115, 0.018444010987877846, 0.044792599976062775, 0.16086743772029877, 0.02797694504261017, 0.779857337474823, 0.03147406131029129, 0.11395788192749023, 0.8855476975440979, 0.002374122617766261, 0.9606412649154663, 0.025963278487324715, 0.1097179502248764, 0.278708815574646, 0.09206219017505646, 0.5195838809013367, 0.9905679225921631, 0.9839003086090088, 0.009370478801429272, 0.9909382462501526, 0.02788429521024227, 0.9699751138687134, 0.20931395888328552, 0.018314970657229424, 0.7744616270065308, 0.052838876843452454, 0.007288120687007904, 0.9383455514907837, 0.006262202747166157, 0.012524405494332314, 0.9706414341926575, 0.012524405494332314, 0.011514072306454182, 0.990210235118866, 0.9880974292755127, 0.9874919652938843, 0.98613440990448, 0.9874717593193054, 0.08587386459112167, 0.10734233260154724, 0.8042417764663696, 0.003302840981632471, 0.9671324491500854, 0.025619402527809143, 0.9814011454582214, 0.9889857172966003, 0.992495059967041, 0.0031112697906792164, 0.0031112697906792164, 0.9756189584732056, 0.006369725335389376, 0.07325183600187302, 0.8630977272987366, 0.057327527552843094, 0.7061232328414917, 0.14372418820858002, 0.1499730795621872, 0.009283251129090786, 0.9886662364006042, 0.004641625564545393, 0.9153668880462646, 0.05847057327628136, 0.012097359634935856, 0.014113586395978928, 0.9794177412986755, 0.01560825016349554, 0.003902062540873885, 0.9907411336898804, 0.6767400503158569, 0.13441026210784912, 0.035946931689977646, 0.15316517651081085, 0.0020644543692469597, 0.9971314668655396, 0.9935379028320312, 0.9859678745269775, 0.004958142060786486, 0.9916284680366516, 0.9566380977630615, 0.9915651082992554, 0.01686345413327217, 0.8094457387924194, 0.026981525123119354, 0.14502570033073425, 0.0031065563671290874, 0.9009013175964355, 0.052811458706855774, 0.046598345041275024, 0.0034755843225866556, 0.0034755843225866556, 0.9835903644561768, 0.006951168645173311, 0.002446557627990842, 0.5835039615631104, 0.40001216530799866, 0.014679345302283764, 0.9585691094398499, 0.013500973582267761, 0.027001947164535522, 0.9947277903556824, 0.003931730519980192, 0.31056270003318787, 0.4774901866912842, 0.19410169124603271, 0.01941016875207424, 0.9474146366119385, 0.00262441742233932, 0.04986393079161644, 0.9608729481697083, 0.02596953883767128, 0.9951589703559875, 0.0028814715333282948, 0.8961376547813416, 0.10085150599479675, 0.023671966046094894, 0.04734393209218979, 0.6477510333061218, 0.28191158175468445, 0.01874650828540325, 0.9560719132423401, 0.9853910207748413, 0.024379270151257515, 0.9690759778022766, 0.006094817537814379, 0.016966428607702255, 0.9444645643234253, 0.011310952715575695, 0.028277382254600525, 0.2730501592159271, 0.6887751817703247, 0.022139202803373337, 0.014759467914700508, 0.9979804158210754, 0.04180203378200531, 0.0029858595225960016, 0.059717193245887756, 0.8957579135894775, 0.004049849230796099, 0.6317765116691589, 0.006074774079024792, 0.3563867509365082, 0.9623168110847473, 0.03084348700940609, 0.006168697495013475, 0.9803914427757263, 0.9724816083908081, 0.01998249813914299, 0.9780005216598511, 0.018304822966456413, 0.002614974742755294, 0.9981215000152588, 0.9959372282028198, 0.07864518463611603, 0.11709395051002502, 0.7672275304794312, 0.034953415393829346, 0.9902278184890747, 0.8362268209457397, 0.026830807328224182, 0.1341540366411209, 0.035885948687791824, 0.9637940526008606, 0.011070330627262592, 0.08192044496536255, 0.004428132437169552, 0.9033389687538147, 0.9941520094871521, 0.002708860905840993, 0.010168354958295822, 0.9609095454216003, 0.025420887395739555, 0.9897205829620361, 0.0043793050572276115, 0.0029195365495979786, 0.9517689347267151, 0.03941374272108078, 0.9471532106399536, 0.03486453369259834, 0.01743226684629917, 0.004385058302432299, 0.052620697766542435, 0.9427874684333801, 0.9923906326293945, 0.138618603348732, 0.6381235718727112, 0.15773841738700867, 0.06452935189008713, 0.9007785320281982, 0.004122556187212467, 0.09481879323720932, 0.96828693151474, 0.004421401768922806, 0.026528410613536835, 0.9895067811012268, 0.005889450199902058, 0.93642258644104, 0.011778900399804115, 0.04711560159921646, 0.0638972744345665, 0.03758663311600685, 0.8945618271827698, 0.003758663311600685, 0.9690936207771301, 0.030049415305256844, 0.0037561769131571054, 0.9986633062362671, 0.06644086539745331, 0.006993775721639395, 0.9266752600669861, 0.0075477599166333675, 0.0037738799583166838, 0.9849826693534851, 0.5080558657646179, 0.01139868889003992, 0.4803733229637146, 0.04745090380311012, 0.8942670822143555, 0.05475104600191116, 0.0034087584353983402, 0.20963864028453827, 0.0017043792176991701, 0.7857188582420349, 0.8725339770317078, 0.12145161628723145, 0.0031960951164364815, 0.9760035276412964, 0.049781735986471176, 0.02866221033036709, 0.7497431039810181, 0.17197325825691223, 0.23119883239269257, 0.761689305305481, 0.006334214471280575, 0.8661117553710938, 0.11996817588806152, 0.011704212985932827, 0.9879412651062012, 0.0013798061991110444, 0.0013798061991110444, 0.00965864397585392, 0.9102931618690491, 0.02238425798714161, 0.059691354632377625, 0.007461419329047203, 0.9301708340644836, 0.017849760130047798, 0.04363274574279785, 0.00793322641402483, 0.9827643632888794, 0.025893229991197586, 0.00345243071205914, 0.9718592166900635, 0.993637204170227, 0.004525204189121723, 0.9910197257995605, 0.0018371718470007181, 0.0073486873880028725, 0.9902356266975403, 0.9993671774864197, 0.002003159373998642, 0.9975733160972595, 0.9939780235290527, 0.013620848767459393, 0.9807011485099792, 0.9442600607872009, 0.04336893931031227, 0.007885261438786983, 0.005913945846259594, 0.02693720906972885, 0.7317941784858704, 0.24019011855125427, 0.8721109628677368, 0.033542729914188385, 0.08843083679676056, 0.006098678335547447, 0.9867604374885559, 0.0018324643606320024, 0.9876983165740967, 0.010994786396622658, 0.002348663518205285, 0.9958332777023315, 0.002348663518205285, 0.9897003173828125, 0.9916820526123047, 0.1391039937734604, 0.001931999810039997, 0.8520119190216064, 0.007727999240159988, 0.4423500597476959, 0.19834406673908234, 0.25684842467308044, 0.1027393713593483, 0.5172654986381531, 0.004355920013040304, 0.478062242269516, 0.4686626195907593, 0.23970940709114075, 0.27351459860801697, 0.01843918487429619, 0.9557027220726013, 0.04155229404568672, 0.05395561829209328, 0.011240753345191479, 0.002248150762170553, 0.9329825639724731, 0.9926004409790039, 0.16292497515678406, 0.06788540631532669, 0.04525693506002426, 0.7218481302261353, 0.005601166747510433, 0.005601166747510433, 0.9886059761047363, 0.017655637115240097, 0.9769452214241028, 0.8483011722564697, 0.14614926278591156, 0.0031771580688655376, 0.8943639397621155, 0.09728768467903137, 0.006827205885201693, 0.9519460201263428, 0.040508341044187546, 0.005381216295063496, 0.19103318452835083, 0.040359124541282654, 0.7641327381134033, 0.016775701195001602, 0.9771845936775208, 0.9788763523101807, 0.005005883518606424, 0.005005883518606424, 0.9861590266227722, 0.7651204466819763, 0.23045796155929565, 0.0030727728735655546, 0.9908406138420105, 0.008055615238845348, 0.604602575302124, 0.3639470338821411, 0.016596931964159012, 0.014225942082703114, 0.9842709898948669, 0.014913196675479412, 0.97978675365448, 0.9898227453231812, 0.004478835966438055, 0.004478835966438055, 0.9221974015235901, 0.009894821792840958, 0.06728479266166687, 0.05992535501718521, 0.0016645932337269187, 0.9371659755706787, 0.0016645932337269187, 0.07031338661909103, 0.0025111923459917307, 0.9266300201416016, 0.9850919246673584, 0.00757763022556901, 0.7337508797645569, 0.21914036571979523, 0.04185827076435089, 0.004924502689391375, 0.7170157432556152, 0.14575402438640594, 0.06817526370286942, 0.06817526370286942, 0.00849371962249279, 0.9852714538574219, 0.9618041515350342, 0.025310635566711426, 0.5195499658584595, 0.3955000936985016, 0.002918819896876812, 0.08172695338726044, 0.023757686838507652, 0.9693136215209961, 0.9901851415634155, 0.04419269412755966, 0.6039668321609497, 0.3505953848361969, 0.9720703959465027, 0.2992299795150757, 0.6982032656669617, 0.8783518075942993, 0.11456762999296188, 0.043178994208574295, 0.09715273976325989, 0.8599816560745239, 0.995502769947052, 0.028601324185729027, 0.8381431698799133, 0.1330583393573761, 0.9737690091133118, 0.33890020847320557, 0.014929523691534996, 0.6419695019721985, 0.004478857386857271, 0.9878761172294617, 0.009011133573949337, 0.9912247061729431, 0.009115802124142647, 0.14585283398628235, 0.8234608173370361, 0.021270204335451126, 0.9928723573684692, 0.996056318283081, 0.9927815794944763, 0.9760428071022034, 0.005741428583860397, 0.017224285751581192, 0.03338516876101494, 0.014307930134236813, 0.9490926861763], \"Term\": [\"accelerated_gradient\", \"accelerated_gradient\", \"accelerated_proximal\", \"accelerated_proximal\", \"active_learning\", \"active_learning\", \"active_learning\", \"active_learning\", \"activity\", \"activity\", \"activity\", \"activity\", \"agent\", \"agent\", \"agent\", \"alex_graf\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"answer\", \"answer\", \"answer\", \"answer\", \"arm\", \"arm\", \"armed\", \"armed\", \"armed\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"autoencoder\", \"auxiliary_variable\", \"auxiliary_variable\", \"auxiliary_variable\", \"bandit\", \"bandit_feedback\", \"bandit_problem\", \"bandit_setting\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_nonparametric\", \"bayesian_nonparametric\", \"bayesian_nonparametric\", \"bayesian_optimization\", \"bayesian_optimization\", \"bayesian_optimization\", \"bayesian_optimization\", \"bianchi\", \"black_variational\", \"black_variational\", \"block_coordinate\", \"block_coordinate\", \"block_coordinate\", \"bubeck\", \"cande\", \"candes\", \"causal\", \"causal\", \"causal\", \"causal\", \"cell\", \"cell\", \"cell\", \"cell\", \"cesa\", \"cluster_assignment\", \"cluster_assignment\", \"cnns\", \"completion\", \"completion\", \"completion\", \"completion\", \"compressed_sensing\", \"compressed_sensing\", \"compressed_sensing\", \"confidence\", \"confidence\", \"confidence\", \"confidence\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convex_relaxation\", \"convex_relaxation\", \"convex_relaxation\", \"convolutional\", \"convolutional\", \"convolutional_layer\", \"convolutional_network\", \"convolutional_network\", \"convolutional_neural\", \"convolutional_neural\", \"convolutional_neural\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"covariance_function\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"cumulative_regret\", \"current_iterate\", \"current_iterate\", \"dantzig\", \"dantzig_selector\", \"data_augmentation\", \"data_augmentation\", \"data_set\", \"data_set\", \"data_set\", \"data_set\", \"decision_maker\", \"decision_making\", \"decision_making\", \"decision_making\", \"decision_making\", \"decoder\", \"decoder\", \"decomposable\", \"decomposable\", \"deep_convolutional\", \"deep_convolutional\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_network\", \"deep_network\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"dimensionality_reduction\", \"dimensionality_reduction\", \"dimensionality_reduction\", \"dirichlet\", \"dirichlet\", \"dirichlet\", \"dirichlet\", \"dirichlet_process\", \"dirichlet_process\", \"dirichlet_process\", \"disagreement\", \"disease\", \"disease\", \"disease\", \"disease\", \"document\", \"document\", \"document\", \"document\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dual_variable\", \"dual_variable\", \"during_training\", \"during_training\", \"during_training\", \"each_round\", \"each_round\", \"each_round\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"encoder\", \"encoder\", \"encoder_decoder\", \"encoder_decoder\", \"estimation_error\", \"estimation_error\", \"estimation_error\", \"exact_recovery\", \"expected_cost\", \"expected_cost\", \"expected_reward\", \"exploration_exploitation\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"feature_map\", \"feature_map\", \"feature_map\", \"feature_map\", \"firing\", \"firing\", \"firing\", \"first_order\", \"first_order\", \"first_order\", \"first_order\", \"foundation_computational\", \"frame\", \"frame\", \"frame\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"game\", \"game\", \"game\", \"game\", \"gaussian_approximation\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs_sampler\", \"gibbs_sampler\", \"gibbs_sampler\", \"gibbs_sampling\", \"gibbs_sampling\", \"gibbs_sampling\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"greedy\", \"greedy\", \"greedy\", \"greedy\", \"greedy_algorithm\", \"greedy_algorithm\", \"greedy_algorithm\", \"gretton\", \"gretton\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"group_lasso\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian_monte\", \"hidden_layer\", \"hidden_layer\", \"hidden_state\", \"hidden_state\", \"hidden_state\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"horizon\", \"horizon\", \"horizon\", \"horizon\", \"iclr\", \"iclr\", \"ilya_sutskever\", \"image_caption\", \"incoherence\", \"input_image\", \"item\", \"item\", \"item\", \"item\", \"iteration_complexity\", \"iteration_complexity\", \"langevin\", \"langevin_dynamic\", \"lasso\", \"lasso\", \"lasso\", \"lasso_journal\", \"learner\", \"learner\", \"learner\", \"learner\", \"least_square\", \"least_square\", \"least_square\", \"lifted\", \"lifted\", \"lifted\", \"line_search\", \"line_search\", \"line_search\", \"line_search\", \"linear_convergence\", \"linear_convergence\", \"linear_convergence\", \"linear_measurement\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"lstm\", \"lstm\", \"lstm_lstm\", \"lstms\", \"machine_translation\", \"machine_translation\", \"mackay\", \"maker\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"market\", \"market\", \"market\", \"market\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"markov_chain_monte_carlo\", \"markov_chain_monte_carlo\", \"markov_chain_monte_carlo\", \"matrix_completion\", \"matrix_completion\", \"maximum_likelihood\", \"maximum_likelihood\", \"maximum_likelihood\", \"maximum_likelihood\", \"mcmc\", \"mcmc\", \"mcmc\", \"mcmc_method\", \"mcmc_method\", \"mdps\", \"mean_field\", \"mean_field\", \"mean_field\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"metropolis\", \"metropolis\", \"metropolis_hastings\", \"mixture_gaussians\", \"mixture_gaussians\", \"mixture_gaussians\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"moment\", \"moment\", \"moment\", \"moment\", \"multi_armed\", \"multi_label\", \"multi_label\", \"multi_label\", \"multi_label\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonsmooth\", \"nuclear\", \"nuclear\", \"nuclear_norm\", \"nuclear_norm\", \"nuclear_norm\", \"object_detection\", \"object_recognition\", \"online_learning\", \"online_learning\", \"online_learning\", \"online_learning\", \"parsing\", \"particle\", \"particle\", \"particle\", \"patch\", \"patch\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"player\", \"player\", \"point_process\", \"point_process\", \"point_process\", \"poisson_process\", \"policy\", \"policy\", \"policy\", \"policy\", \"polytope\", \"polytope\", \"polytope\", \"pooling\", \"pooling\", \"pooling\", \"pooling_layer\", \"population\", \"population\", \"population\", \"population\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_mean\", \"posterior_mean\", \"posterior_mean\", \"posterior_predictive\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"price\", \"price\", \"price\", \"price\", \"primal\", \"primal\", \"primal\", \"primal_dual\", \"privacy\", \"privacy\", \"privacy\", \"private\", \"private\", \"private\", \"probability_least\", \"probability_least\", \"probability_least\", \"probability_measure\", \"probability_measure\", \"probability_measure\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"proximal\", \"proximal\", \"proximal\", \"quadrature\", \"query\", \"query\", \"query\", \"query\", \"random_walk\", \"random_walk\", \"random_walk\", \"rank_approximation\", \"rank_approximation\", \"rank_approximation\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"rate_convergence\", \"rate_convergence\", \"rate_convergence\", \"rate_convergence\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery_guarantee\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent_convolutional\", \"recurrent_network\", \"recurrent_network\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"regret\", \"regret_bound\", \"regret_bound\", \"regret_minimization\", \"regret_regret\", \"regret_regret\", \"regularization_parameter\", \"regularization_parameter\", \"regularization_parameter\", \"regularization_parameter\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"restricted_strong\", \"reward\", \"reward\", \"reward\", \"reward_function\", \"reward_function\", \"reward_function\", \"rnns\", \"robert_schapire\", \"round\", \"round\", \"round\", \"round\", \"running_time\", \"running_time\", \"running_time\", \"running_time\", \"sample_complexity\", \"sample_complexity\", \"sample_complexity\", \"sample_size\", \"sample_size\", \"sample_size\", \"sample_size\", \"sampler\", \"sampler\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"semantic_segmentation\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"sentence\", \"sentence\", \"sentence\", \"sequence_sequence\", \"sequence_sequence\", \"singular\", \"singular\", \"singular\", \"singular_value\", \"singular_value\", \"singular_value\", \"sparse_recovery\", \"sparse_recovery\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"speech_recognition\", \"speech_recognition\", \"squared_exponential\", \"stack\", \"stack\", \"stack\", \"stationary_distribution\", \"stationary_distribution\", \"stationary_distribution\", \"statistical_guarantee\", \"statistical_guarantee\", \"step_size\", \"step_size\", \"step_size\", \"step_size\", \"stochastic_dual\", \"stochastic_dual\", \"stochastic_gradient_langevin_dynamic\", \"strong_convexity\", \"strong_convexity\", \"strong_convexity\", \"strongly_convex\", \"strongly_convex\", \"strongly_convex\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular_function\", \"submodular_function\", \"submodular_function\", \"submodular_maximization\", \"submodular_maximization\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"support_vector\", \"support_vector\", \"support_vector\", \"support_vector\", \"sutskever\", \"sutskever\", \"taylor_expansion\", \"taylor_expansion\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"texture\", \"texture\", \"time_horizon\", \"time_step\", \"time_step\", \"time_step\", \"titsias\", \"topic_model\", \"topic_model\", \"true_posterior\", \"true_posterior\", \"unlabeled_data\", \"unlabeled_data\", \"unlabeled_data\", \"upper_confidence\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"vershynin\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"very_deep\", \"visual_recognition\", \"visual_recognition\", \"walk\", \"walk\", \"walk\", \"walk\", \"weighted_majority\", \"welfare\", \"welling_bayesian\", \"wolfe\", \"wolfe\", \"wolfe\", \"yoshua_bengio\", \"yoshua_bengio\", \"yoshua_bengio\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 4, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el648731124192953041061328652\", ldavis_el648731124192953041061328652_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el648731124192953041061328652\", ldavis_el648731124192953041061328652_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el648731124192953041061328652\", ldavis_el648731124192953041061328652_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.131577 -0.104061       1        1  27.028528\n",
       "3      0.032065 -0.054060       2        1  25.891464\n",
       "1     -0.103329  0.143815       3        1  23.653622\n",
       "0      0.202841  0.014305       4        1  23.426386, topic_info=     Category         Freq                      Term        Total  loglift  \\\n",
       "609   Default  1223.000000                    regret  1223.000000  30.0000   \n",
       "3230  Default   929.000000          gaussian_process   929.000000  29.0000   \n",
       "3192  Default   703.000000                    bandit   703.000000  28.0000   \n",
       "3105  Default   763.000000         matrix_completion   763.000000  27.0000   \n",
       "2180  Default   676.000000             convolutional   676.000000  26.0000   \n",
       "3140  Default   724.000000               rank_matrix   724.000000  25.0000   \n",
       "3185  Default   673.000000           active_learning   673.000000  24.0000   \n",
       "3263  Default   685.000000                    policy   685.000000  23.0000   \n",
       "2333  Default   579.000000                 recurrent   579.000000  22.0000   \n",
       "2336  Default   544.000000          recurrent_neural   544.000000  21.0000   \n",
       "270   Default   545.000000                    reward   545.000000  20.0000   \n",
       "2221  Default   594.000000           fully_connected   594.000000  19.0000   \n",
       "3287  Default   600.000000                submodular   600.000000  18.0000   \n",
       "610   Default   499.000000              regret_bound   499.000000  17.0000   \n",
       "2272  Default   484.000000                      lstm   484.000000  16.0000   \n",
       "123   Default   550.000000                      game   550.000000  15.0000   \n",
       "335   Default   804.000000     variational_inference   804.000000  14.0000   \n",
       "3937  Default   502.000000              hidden_layer   502.000000  13.0000   \n",
       "1311  Default   548.000000               hidden_unit   548.000000  12.0000   \n",
       "7     Default   483.000000                     agent   483.000000  11.0000   \n",
       "74    Default   611.000000             deep_learning   611.000000  10.0000   \n",
       "5038  Default   425.000000           reward_function   425.000000   9.0000   \n",
       "3152  Default   918.000000         sample_complexity   918.000000   8.0000   \n",
       "2183  Default   429.000000      convolutional_neural   429.000000   7.0000   \n",
       "1737  Default   410.000000           during_training   410.000000   6.0000   \n",
       "2366  Default   585.000000            singular_value   585.000000   5.0000   \n",
       "1409  Default   631.000000               random_walk   631.000000   4.0000   \n",
       "1406  Default   586.000000                  proposal   586.000000   3.0000   \n",
       "3145  Default   507.000000  regularization_parameter   507.000000   2.0000   \n",
       "2096  Default   444.000000              segmentation   444.000000   1.0000   \n",
       "...       ...          ...                       ...          ...      ...   \n",
       "3937   Topic4   487.064941              hidden_layer   502.074738   1.4210   \n",
       "294    Topic4   233.305664        speech_recognition   238.440109   1.4295   \n",
       "771    Topic4   203.446777                   dropout   207.522583   1.4315   \n",
       "2221   Topic4   566.859802           fully_connected   594.100342   1.4044   \n",
       "4084   Topic4   166.078125         sequence_sequence   169.917404   1.4285   \n",
       "313    Topic4   204.117874                   texture   210.458206   1.4207   \n",
       "1311   Topic4   514.955688               hidden_unit   548.838318   1.3876   \n",
       "2189   Topic4   169.970474         data_augmentation   174.732651   1.4237   \n",
       "5844   Topic4   163.590424                   decoder   167.966812   1.4249   \n",
       "2096   Topic4   415.358704              segmentation   444.810028   1.3828   \n",
       "74     Topic4   544.980591             deep_learning   611.560974   1.3360   \n",
       "3383   Topic4   187.850922                     patch   195.062424   1.4136   \n",
       "75     Topic4   316.353516               deep_neural   342.164093   1.3729   \n",
       "2075   Topic4   408.066071                     pixel   451.657684   1.3498   \n",
       "2747   Topic4   214.990280                   pooling   228.047150   1.3923   \n",
       "1825   Topic4   299.646423               multi_label   334.911926   1.3400   \n",
       "3422   Topic4   199.373093             yoshua_bengio   209.673935   1.4009   \n",
       "1406   Topic4   460.981293                  proposal   586.723877   1.2101   \n",
       "2679   Topic4   269.106293               feature_map   316.624451   1.2887   \n",
       "5097   Topic4   295.866180              hidden_state   382.200989   1.1953   \n",
       "3353   Topic4   465.142242          generative_model   796.331299   0.9136   \n",
       "279    Topic4   319.360474           semi_supervised   441.921204   1.1265   \n",
       "2783   Topic4   284.137207                   spatial   371.663177   1.1828   \n",
       "2685   Topic4   266.887268                     frame   339.407227   1.2109   \n",
       "694    Topic4   239.488037            unlabeled_data   277.912903   1.3025   \n",
       "134    Topic4   411.512146              ground_truth   792.942261   0.7954   \n",
       "2203   Topic4   335.162537                  document   530.989441   0.9912   \n",
       "4689   Topic4   287.272614               topic_model   411.055084   1.0930   \n",
       "473    Topic4   321.851990                 embedding   622.897888   0.7910   \n",
       "17     Topic4   250.190048                    answer   375.018311   1.0466   \n",
       "\n",
       "      logprob  \n",
       "609   30.0000  \n",
       "3230  29.0000  \n",
       "3192  28.0000  \n",
       "3105  27.0000  \n",
       "2180  26.0000  \n",
       "3140  25.0000  \n",
       "3185  24.0000  \n",
       "3263  23.0000  \n",
       "2333  22.0000  \n",
       "2336  21.0000  \n",
       "270   20.0000  \n",
       "2221  19.0000  \n",
       "3287  18.0000  \n",
       "610   17.0000  \n",
       "2272  16.0000  \n",
       "123   15.0000  \n",
       "335   14.0000  \n",
       "3937  13.0000  \n",
       "1311  12.0000  \n",
       "7     11.0000  \n",
       "74    10.0000  \n",
       "5038   9.0000  \n",
       "3152   8.0000  \n",
       "2183   7.0000  \n",
       "1737   6.0000  \n",
       "2366   5.0000  \n",
       "1409   4.0000  \n",
       "1406   3.0000  \n",
       "3145   2.0000  \n",
       "2096   1.0000  \n",
       "...       ...  \n",
       "3937  -5.3565  \n",
       "294   -6.0926  \n",
       "771   -6.2295  \n",
       "2221  -5.2048  \n",
       "4084  -6.4325  \n",
       "313   -6.2262  \n",
       "1311  -5.3008  \n",
       "2189  -6.4093  \n",
       "5844  -6.4475  \n",
       "2096  -5.5158  \n",
       "74    -5.2442  \n",
       "3383  -6.3093  \n",
       "75    -5.7881  \n",
       "2075  -5.5335  \n",
       "2747  -6.1743  \n",
       "1825  -5.8423  \n",
       "3422  -6.2497  \n",
       "1406  -5.4116  \n",
       "2679  -5.9498  \n",
       "5097  -5.8550  \n",
       "3353  -5.4026  \n",
       "279   -5.7786  \n",
       "2783  -5.8955  \n",
       "2685  -5.9581  \n",
       "694   -6.0664  \n",
       "134   -5.5251  \n",
       "2203  -5.7303  \n",
       "4689  -5.8845  \n",
       "473   -5.7708  \n",
       "17    -6.0227  \n",
       "\n",
       "[293 rows x 6 columns], token_table=      Topic      Freq                      Term\n",
       "term                                           \n",
       "4737      1  0.984572      accelerated_gradient\n",
       "4737      4  0.014918      accelerated_gradient\n",
       "4738      1  0.981400      accelerated_proximal\n",
       "4738      4  0.018174      accelerated_proximal\n",
       "3185      1  0.002968           active_learning\n",
       "3185      2  0.035620           active_learning\n",
       "3185      3  0.961727           active_learning\n",
       "3185      4  0.001484           active_learning\n",
       "3525      1  0.008983                  activity\n",
       "3525      2  0.835395                  activity\n",
       "3525      3  0.022457                  activity\n",
       "3525      4  0.134741                  activity\n",
       "7         2  0.002070                     agent\n",
       "7         3  0.983148                     agent\n",
       "7         4  0.014489                     agent\n",
       "5876      4  0.987521                 alex_graf\n",
       "3023      1  0.978048  alternating_minimization\n",
       "3023      2  0.005345  alternating_minimization\n",
       "3023      4  0.016034  alternating_minimization\n",
       "17        1  0.039998                    answer\n",
       "17        2  0.013333                    answer\n",
       "17        3  0.279986                    answer\n",
       "17        4  0.666634                    answer\n",
       "4180      3  0.980010                       arm\n",
       "4180      4  0.016897                       arm\n",
       "3190      1  0.016794                     armed\n",
       "3190      2  0.005598                     armed\n",
       "3190      3  0.974078                     armed\n",
       "2440      1  0.004218              asynchronous\n",
       "2440      2  0.923641              asynchronous\n",
       "...     ...       ...                       ...\n",
       "4393      2  0.878352            true_posterior\n",
       "4393      4  0.114568            true_posterior\n",
       "694       2  0.043179            unlabeled_data\n",
       "694       3  0.097153            unlabeled_data\n",
       "694       4  0.859982            unlabeled_data\n",
       "4248      3  0.995503          upper_confidence\n",
       "335       1  0.028601     variational_inference\n",
       "335       2  0.838143     variational_inference\n",
       "335       4  0.133058     variational_inference\n",
       "5749      1  0.973769                 vershynin\n",
       "2124      1  0.338900                    vertex\n",
       "2124      2  0.014930                    vertex\n",
       "2124      3  0.641970                    vertex\n",
       "2124      4  0.004479                    vertex\n",
       "2405      4  0.987876                 very_deep\n",
       "1919      2  0.009011        visual_recognition\n",
       "1919      4  0.991225        visual_recognition\n",
       "1469      1  0.009116                      walk\n",
       "1469      2  0.145853                      walk\n",
       "1469      3  0.823461                      walk\n",
       "1469      4  0.021270                      walk\n",
       "5836      3  0.992872         weighted_majority\n",
       "3015      3  0.996056                   welfare\n",
       "1470      2  0.992782          welling_bayesian\n",
       "4002      1  0.976043                     wolfe\n",
       "4002      2  0.005741                     wolfe\n",
       "4002      3  0.017224                     wolfe\n",
       "3422      1  0.033385             yoshua_bengio\n",
       "3422      2  0.014308             yoshua_bengio\n",
       "3422      4  0.949093             yoshua_bengio\n",
       "\n",
       "[655 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 4, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation of the Visualization \n",
    "\n",
    "\n",
    "\n",
    "- Left Panel: \n",
    "The labeld Intertopic Distance Map, circles represent different topics and the distance between them. Similar topics appear closer and the dissimilar topics farther. The relative size of a topic's circle in the plot corresponds to the relative frequency of the topic in the corpus. An individual topic may be selected for closer scrutiny by clicking on its circle, or entering its number in the \"selected topic\" box in the upper-left.\n",
    "\n",
    "\n",
    "\n",
    "- Right Panel:\n",
    "It includes the bar chart of the top 30 terms. When no topic is selected in the plot on the left, the bar chart shows the top-30 most \"salient\" terms in the corpus. A term's saliency is a measure of both how frequent the term is in the corpus and how \"distinctive\" it is in distinguishing between different topics. Selecting each topic on the right, modifies the bar chart to show the \"relevant\" terms for the selected topic. \n",
    "\n",
    "Relevence is defined as in footer 2 and can be tuned by parameter $\\lambda$.\n",
    "- Smaller $\\lambda$ gives higher weight to the term's distinctiveness.\n",
    "- larger $\\lambda$ corresponds to probablity of the term occurance per topics.\n",
    "\n",
    "Therefore, to get a better sense of terms per topic we use $\\lambda = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Top Words in the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model, num_topics, top_words):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = top_words);\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convolutional</td>\n",
       "      <td>regret</td>\n",
       "      <td>matrix_completion</td>\n",
       "      <td>gaussian_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fully_connected</td>\n",
       "      <td>bandit</td>\n",
       "      <td>rank_matrix</td>\n",
       "      <td>variational_inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recurrent</td>\n",
       "      <td>policy</td>\n",
       "      <td>convergence_rate</td>\n",
       "      <td>markov_chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>active_learning</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>posterior_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recurrent_neural</td>\n",
       "      <td>submodular</td>\n",
       "      <td>singular_value</td>\n",
       "      <td>sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>reward</td>\n",
       "      <td>step_size</td>\n",
       "      <td>mcmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>game</td>\n",
       "      <td>regularization_parameter</td>\n",
       "      <td>covariance_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lstm</td>\n",
       "      <td>regret_bound</td>\n",
       "      <td>sample_complexity</td>\n",
       "      <td>graphical_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>generative_model</td>\n",
       "      <td>query</td>\n",
       "      <td>recovery</td>\n",
       "      <td>gibbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>proposal</td>\n",
       "      <td>item</td>\n",
       "      <td>strongly_convex</td>\n",
       "      <td>mixture_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>convolutional_neural</td>\n",
       "      <td>random_walk</td>\n",
       "      <td>line_search</td>\n",
       "      <td>neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>segmentation</td>\n",
       "      <td>agent</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>mean_field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ground_truth</td>\n",
       "      <td>greedy</td>\n",
       "      <td>data_set</td>\n",
       "      <td>exponential_family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pixel</td>\n",
       "      <td>round</td>\n",
       "      <td>nuclear_norm</td>\n",
       "      <td>step_size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>during_training</td>\n",
       "      <td>online_learning</td>\n",
       "      <td>covariance_matrix</td>\n",
       "      <td>bayesian_inference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sentence</td>\n",
       "      <td>sample_complexity</td>\n",
       "      <td>rate_convergence</td>\n",
       "      <td>marginal_likelihood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>convolutional_network</td>\n",
       "      <td>vertex</td>\n",
       "      <td>graphical_model</td>\n",
       "      <td>gibbs_sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>document</td>\n",
       "      <td>reward_function</td>\n",
       "      <td>tensor</td>\n",
       "      <td>gibbs_sampler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>deep_network</td>\n",
       "      <td>time_step</td>\n",
       "      <td>least_square</td>\n",
       "      <td>moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>embedding</td>\n",
       "      <td>greedy_algorithm</td>\n",
       "      <td>completion</td>\n",
       "      <td>embedding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic # 01         Topic # 02                Topic # 03  \\\n",
       "0           convolutional             regret         matrix_completion   \n",
       "1         fully_connected             bandit               rank_matrix   \n",
       "2               recurrent             policy          convergence_rate   \n",
       "3           deep_learning    active_learning          gradient_descent   \n",
       "4        recurrent_neural         submodular            singular_value   \n",
       "5             hidden_unit             reward                 step_size   \n",
       "6            hidden_layer               game  regularization_parameter   \n",
       "7                    lstm       regret_bound         sample_complexity   \n",
       "8        generative_model              query                  recovery   \n",
       "9                proposal               item           strongly_convex   \n",
       "10   convolutional_neural        random_walk               line_search   \n",
       "11           segmentation              agent       logistic_regression   \n",
       "12           ground_truth             greedy                  data_set   \n",
       "13                  pixel              round              nuclear_norm   \n",
       "14        during_training    online_learning         covariance_matrix   \n",
       "15               sentence  sample_complexity          rate_convergence   \n",
       "16  convolutional_network             vertex           graphical_model   \n",
       "17               document    reward_function                    tensor   \n",
       "18           deep_network          time_step              least_square   \n",
       "19              embedding   greedy_algorithm                completion   \n",
       "\n",
       "                Topic # 04  \n",
       "0         gaussian_process  \n",
       "1    variational_inference  \n",
       "2             markov_chain  \n",
       "3   posterior_distribution  \n",
       "4                  sampler  \n",
       "5                     mcmc  \n",
       "6        covariance_matrix  \n",
       "7          graphical_model  \n",
       "8                    gibbs  \n",
       "9            mixture_model  \n",
       "10                  neuron  \n",
       "11              mean_field  \n",
       "12      exponential_family  \n",
       "13               step_size  \n",
       "14      bayesian_inference  \n",
       "15     marginal_likelihood  \n",
       "16          gibbs_sampling  \n",
       "17           gibbs_sampler  \n",
       "18                  moment  \n",
       "19               embedding  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_topics(model, num_topics, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Labels for the Topics\n",
    "\n",
    "We can manually generate human-interpretable labels for each topic by looking at the terms that appear more in each topic.\n",
    "\n",
    "\n",
    "We use LdaModel's \"show_topic\" method that returns **Word-probability pairs** for the most relevant words generated by the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(lda_model, topic_number, topn, output=True):\n",
    "    \"\"\"\n",
    "    accept a ldamodel, a topic number and topn vocabs of interest\n",
    "    prints a formatted list of the topn terms\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
    "        terms += [term]\n",
    "        if output:\n",
    "            print(u'{:30} {:.3f}'.format(term, round(frequency, 3)))\n",
    "    \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                      frequency\n",
      "\n",
      "\n",
      "Topic 0 |---------------------------\n",
      "\n",
      "convolutional                  0.007\n",
      "fully_connected                0.005\n",
      "recurrent                      0.005\n",
      "deep_learning                  0.005\n",
      "recurrent_neural               0.005\n",
      "hidden_unit                    0.005\n",
      "hidden_layer                   0.005\n",
      "lstm                           0.005\n",
      "generative_model               0.005\n",
      "proposal                       0.004\n",
      "\n",
      "Topic 1 |---------------------------\n",
      "\n",
      "regret                         0.012\n",
      "bandit                         0.007\n",
      "policy                         0.006\n",
      "active_learning                0.006\n",
      "submodular                     0.005\n",
      "reward                         0.005\n",
      "game                           0.005\n",
      "regret_bound                   0.005\n",
      "query                          0.005\n",
      "item                           0.005\n",
      "\n",
      "Topic 2 |---------------------------\n",
      "\n",
      "matrix_completion              0.006\n",
      "rank_matrix                    0.006\n",
      "convergence_rate               0.006\n",
      "gradient_descent               0.005\n",
      "singular_value                 0.004\n",
      "step_size                      0.004\n",
      "regularization_parameter       0.004\n",
      "sample_complexity              0.004\n",
      "recovery                       0.004\n",
      "strongly_convex                0.004\n",
      "\n",
      "Topic 3 |---------------------------\n",
      "\n",
      "gaussian_process               0.008\n",
      "variational_inference          0.006\n",
      "markov_chain                   0.004\n",
      "posterior_distribution         0.004\n",
      "sampler                        0.003\n",
      "mcmc                           0.003\n",
      "covariance_matrix              0.003\n",
      "graphical_model                0.003\n",
      "gibbs                          0.003\n",
      "mixture_model                  0.003\n"
     ]
    }
   ],
   "source": [
    "topic_summaries = []\n",
    "\n",
    "print(u'{:25} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print('\\nTopic '+str(i)+' |---------------------------\\n')\n",
    "    tmp = explore_topic(model,topic_number=i, topn=10, output=True )\n",
    "#     print tmp[:5]\n",
    "    topic_summaries += [tmp[:5]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Generate Topic Labels\n",
    "\n",
    "Based on the most probable words generated by each topic, we assign human-interpretable labels for the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = {0: 'Statistics', 1:'Numerical Analysis', 2:'Online Learning', 3:'Deep Learning'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
